{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4deee725",
   "metadata": {},
   "source": [
    "# Biased data in BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0237b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640485fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def json2Dataframe(path):\n",
    "    dataset = []\n",
    "    with open(path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    for i, line in enumerate(json_data):\n",
    "        tmpdict = {\n",
    "        'premise': json_data[str(i)]['premise'],\n",
    "        'hypothesis': json_data[str(i)]['hypothesis'],\n",
    "        'gold_label': json_data[str(i)]['gold_label']\n",
    "        }\n",
    "        dataset.append(tmpdict)\n",
    "    df = pd.DataFrame(dataset)\n",
    "    return df\n",
    "\n",
    "def generateBiasDataset(df_train, MAX_LENGTH=64, isTrain=True):\n",
    "    df_train = rmvNeg(df_train)\n",
    "    input_ids, labels = token2ids(df_train, MAX_LENGTH)\n",
    "    attn_masks = createAttnMask(input_ids)\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attn_masks = torch.tensor(attn_masks)\n",
    "    labels = torch.tensor(labels)\n",
    "    data = TensorDataset(input_ids, attn_masks, labels)\n",
    "    if isTrain:\n",
    "        sampler = RandomSampler(data)\n",
    "    else:\n",
    "        sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(data, sampler=sampler, batch_size=32)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe295b36",
   "metadata": {},
   "source": [
    "# Note\n",
    "### Here I used biased training dataset(remove word related to \"female\"), but used unbiased dataset for validation and test, you can check that the length of train_dataloader is different with training dataset in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4a822f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train loader: 13197\n",
      "length of val loader: 308\n"
     ]
    }
   ],
   "source": [
    "df = json2Dataframe('./bias_dataset/snli_1.0_train.jsonl')\n",
    "train_dataloader = generateBiasDataset(df)\n",
    "val_dataloader = generateDataset(dataPath='./dataset/snli_1.0_dev.jsonl', isTrain=False)\n",
    "print(\"length of train loader: {}\".format(len(train_dataloader)))\n",
    "print(\"length of val loader: {}\".format(len(val_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3509bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac561eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from train_epoch import evaluate\n",
    "import torch.nn as nn\n",
    "import time\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f27d973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   200   |   0.581226   |     -      |     -     |   42.55  \n",
      "   1    |   400   |   0.470333   |     -      |     -     |   35.18  \n",
      "   1    |   600   |   0.447276   |     -      |     -     |   35.31  \n",
      "   1    |   800   |   0.433761   |     -      |     -     |   35.32  \n",
      "   1    |  1000   |   0.419696   |     -      |     -     |   35.45  \n",
      "   1    |  1200   |   0.397304   |     -      |     -     |   35.43  \n",
      "   1    |  1400   |   0.393932   |     -      |     -     |   35.35  \n",
      "   1    |  1600   |   0.390886   |     -      |     -     |   35.38  \n",
      "   1    |  1800   |   0.379350   |     -      |     -     |   35.37  \n",
      "   1    |  2000   |   0.371469   |     -      |     -     |   35.35  \n",
      "   1    |  2200   |   0.375487   |     -      |     -     |   35.35  \n",
      "   1    |  2400   |   0.373932   |     -      |     -     |   35.36  \n",
      "   1    |  2600   |   0.357012   |     -      |     -     |   35.35  \n",
      "   1    |  2800   |   0.349090   |     -      |     -     |   35.36  \n",
      "   1    |  3000   |   0.360648   |     -      |     -     |   35.37  \n",
      "   1    |  3200   |   0.355734   |     -      |     -     |   35.39  \n",
      "   1    |  3400   |   0.358211   |     -      |     -     |   35.38  \n",
      "   1    |  3600   |   0.351246   |     -      |     -     |   35.36  \n",
      "   1    |  3800   |   0.355504   |     -      |     -     |   35.36  \n",
      "   1    |  4000   |   0.345062   |     -      |     -     |   35.37  \n",
      "   1    |  4200   |   0.350255   |     -      |     -     |   35.39  \n",
      "   1    |  4400   |   0.340628   |     -      |     -     |   35.39  \n",
      "   1    |  4600   |   0.344530   |     -      |     -     |   35.36  \n",
      "   1    |  4800   |   0.338773   |     -      |     -     |   35.36  \n",
      "   1    |  5000   |   0.340593   |     -      |     -     |   35.38  \n",
      "   1    |  5200   |   0.342384   |     -      |     -     |   35.40  \n",
      "   1    |  5400   |   0.327819   |     -      |     -     |   35.36  \n",
      "   1    |  5600   |   0.325235   |     -      |     -     |   35.38  \n",
      "   1    |  5800   |   0.341801   |     -      |     -     |   35.35  \n",
      "   1    |  6000   |   0.327443   |     -      |     -     |   35.38  \n",
      "   1    |  6200   |   0.330966   |     -      |     -     |   35.39  \n",
      "   1    |  6400   |   0.336922   |     -      |     -     |   35.38  \n",
      "   1    |  6600   |   0.323143   |     -      |     -     |   35.38  \n",
      "   1    |  6800   |   0.322687   |     -      |     -     |   35.37  \n",
      "   1    |  7000   |   0.317497   |     -      |     -     |   35.40  \n",
      "   1    |  7200   |   0.329122   |     -      |     -     |   35.37  \n",
      "   1    |  7400   |   0.315043   |     -      |     -     |   35.36  \n",
      "   1    |  7600   |   0.334063   |     -      |     -     |   35.36  \n",
      "   1    |  7800   |   0.323114   |     -      |     -     |   35.41  \n",
      "   1    |  8000   |   0.340403   |     -      |     -     |   35.38  \n",
      "   1    |  8200   |   0.314993   |     -      |     -     |   35.37  \n",
      "   1    |  8400   |   0.312703   |     -      |     -     |   35.40  \n",
      "   1    |  8600   |   0.324582   |     -      |     -     |   35.36  \n",
      "   1    |  8800   |   0.307513   |     -      |     -     |   35.38  \n",
      "   1    |  9000   |   0.312814   |     -      |     -     |   35.37  \n",
      "   1    |  9200   |   0.315251   |     -      |     -     |   35.38  \n",
      "   1    |  9400   |   0.315956   |     -      |     -     |   35.38  \n",
      "   1    |  9600   |   0.312109   |     -      |     -     |   35.39  \n",
      "   1    |  9800   |   0.321298   |     -      |     -     |   35.38  \n",
      "   1    |  10000  |   0.310236   |     -      |     -     |   35.39  \n",
      "   1    |  10200  |   0.312535   |     -      |     -     |   35.38  \n",
      "   1    |  10400  |   0.309260   |     -      |     -     |   35.39  \n",
      "   1    |  10600  |   0.312614   |     -      |     -     |   35.38  \n",
      "   1    |  10800  |   0.304283   |     -      |     -     |   35.37  \n",
      "   1    |  11000  |   0.313545   |     -      |     -     |   35.36  \n",
      "   1    |  11200  |   0.305870   |     -      |     -     |   35.38  \n",
      "   1    |  11400  |   0.306380   |     -      |     -     |   35.38  \n",
      "   1    |  11600  |   0.317019   |     -      |     -     |   35.39  \n",
      "   1    |  11800  |   0.300146   |     -      |     -     |   35.36  \n",
      "   1    |  12000  |   0.294623   |     -      |     -     |   35.35  \n",
      "   1    |  12200  |   0.295048   |     -      |     -     |   35.36  \n",
      "   1    |  12400  |   0.280158   |     -      |     -     |   35.39  \n",
      "   1    |  12600  |   0.309230   |     -      |     -     |   35.37  \n",
      "   1    |  12800  |   0.289629   |     -      |     -     |   35.36  \n",
      "   1    |  13000  |   0.300122   |     -      |     -     |   35.37  \n",
      "   1    |  13196  |   0.299782   |     -      |     -     |   34.65  \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.341202   |  4.330927  |   59.22   |  2356.83 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   200   |   0.233949   |     -      |     -     |   35.49  \n",
      "   2    |   400   |   0.222638   |     -      |     -     |   35.38  \n",
      "   2    |   600   |   0.231941   |     -      |     -     |   35.38  \n",
      "   2    |   800   |   0.215316   |     -      |     -     |   35.40  \n",
      "   2    |  1000   |   0.241883   |     -      |     -     |   35.36  \n",
      "   2    |  1200   |   0.226937   |     -      |     -     |   35.40  \n",
      "   2    |  1400   |   0.235101   |     -      |     -     |   35.40  \n",
      "   2    |  1600   |   0.231122   |     -      |     -     |   35.37  \n",
      "   2    |  1800   |   0.240304   |     -      |     -     |   35.37  \n",
      "   2    |  2000   |   0.233608   |     -      |     -     |   35.38  \n",
      "   2    |  2200   |   0.239622   |     -      |     -     |   35.37  \n",
      "   2    |  2400   |   0.244668   |     -      |     -     |   35.38  \n",
      "   2    |  2600   |   0.231208   |     -      |     -     |   35.38  \n",
      "   2    |  2800   |   0.245516   |     -      |     -     |   35.38  \n",
      "   2    |  3000   |   0.237949   |     -      |     -     |   35.38  \n",
      "   2    |  3200   |   0.229694   |     -      |     -     |   35.38  \n",
      "   2    |  3400   |   0.226970   |     -      |     -     |   35.37  \n",
      "   2    |  3600   |   0.240118   |     -      |     -     |   35.35  \n",
      "   2    |  3800   |   0.230494   |     -      |     -     |   35.38  \n",
      "   2    |  4000   |   0.235154   |     -      |     -     |   35.36  \n",
      "   2    |  4200   |   0.229615   |     -      |     -     |   35.37  \n",
      "   2    |  4400   |   0.229811   |     -      |     -     |   35.39  \n",
      "   2    |  4600   |   0.236012   |     -      |     -     |   35.38  \n",
      "   2    |  4800   |   0.230196   |     -      |     -     |   35.37  \n",
      "   2    |  5000   |   0.238101   |     -      |     -     |   35.36  \n",
      "   2    |  5200   |   0.235847   |     -      |     -     |   35.37  \n",
      "   2    |  5400   |   0.231343   |     -      |     -     |   35.39  \n",
      "   2    |  5600   |   0.242137   |     -      |     -     |   35.36  \n",
      "   2    |  5800   |   0.220177   |     -      |     -     |   35.38  \n",
      "   2    |  6000   |   0.227680   |     -      |     -     |   35.37  \n",
      "   2    |  6200   |   0.238338   |     -      |     -     |   35.36  \n",
      "   2    |  6400   |   0.233652   |     -      |     -     |   35.40  \n",
      "   2    |  6600   |   0.228907   |     -      |     -     |   35.38  \n",
      "   2    |  6800   |   0.229077   |     -      |     -     |   35.37  \n",
      "   2    |  7000   |   0.217111   |     -      |     -     |   35.38  \n",
      "   2    |  7200   |   0.231334   |     -      |     -     |   35.39  \n",
      "   2    |  7400   |   0.231600   |     -      |     -     |   35.39  \n",
      "   2    |  7600   |   0.229068   |     -      |     -     |   35.35  \n",
      "   2    |  7800   |   0.230737   |     -      |     -     |   35.36  \n",
      "   2    |  8000   |   0.224738   |     -      |     -     |   35.38  \n",
      "   2    |  8200   |   0.201943   |     -      |     -     |   35.39  \n",
      "   2    |  8400   |   0.226113   |     -      |     -     |   35.39  \n",
      "   2    |  8600   |   0.225367   |     -      |     -     |   35.38  \n",
      "   2    |  8800   |   0.229254   |     -      |     -     |   35.38  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2    |  9000   |   0.227745   |     -      |     -     |   35.38  \n",
      "   2    |  9200   |   0.226175   |     -      |     -     |   35.39  \n",
      "   2    |  9400   |   0.237898   |     -      |     -     |   35.41  \n",
      "   2    |  9600   |   0.227972   |     -      |     -     |   35.39  \n",
      "   2    |  9800   |   0.223607   |     -      |     -     |   35.36  \n",
      "   2    |  10000  |   0.221107   |     -      |     -     |   35.38  \n",
      "   2    |  10200  |   0.224030   |     -      |     -     |   35.36  \n",
      "   2    |  10400  |   0.215053   |     -      |     -     |   35.38  \n",
      "   2    |  10600  |   0.220768   |     -      |     -     |   35.36  \n",
      "   2    |  10800  |   0.218026   |     -      |     -     |   35.37  \n",
      "   2    |  11000  |   0.227475   |     -      |     -     |   35.37  \n",
      "   2    |  11200  |   0.221499   |     -      |     -     |   35.38  \n",
      "   2    |  11400  |   0.228994   |     -      |     -     |   35.38  \n",
      "   2    |  11600  |   0.232926   |     -      |     -     |   35.39  \n",
      "   2    |  11800  |   0.205895   |     -      |     -     |   35.40  \n",
      "   2    |  12000  |   0.218205   |     -      |     -     |   35.37  \n",
      "   2    |  12200  |   0.227398   |     -      |     -     |   35.38  \n",
      "   2    |  12400  |   0.220561   |     -      |     -     |   35.40  \n",
      "   2    |  12600  |   0.218863   |     -      |     -     |   35.36  \n",
      "   2    |  12800  |   0.224266   |     -      |     -     |   35.38  \n",
      "   2    |  13000  |   0.223255   |     -      |     -     |   35.36  \n",
      "   2    |  13196  |   0.229055   |     -      |     -     |   34.66  \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.228684   |  5.422687  |   59.47   |  2350.21 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from train_epoch import train, evaluate, bert_predict\n",
    "\n",
    "epochs = 2\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Set up the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "train_losses, val_losses, val_acc = train(model, loss_fn, optimizer, scheduler, train_dataloader, val_dataloader, epochs=epochs, evaluation=True, device=device, FINETUNE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28cff2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAFBCAYAAAAyrwinAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA/r0lEQVR4nO3dd3zV9dn/8ddFAEEMDkRQEUHFAYIokargQNGCiqDVOnBWS3HVcVtFvatVf97VLlsn4mgVB1oVS917L4ICAoIiDiIqo4ACIiS5fn9cJ806CTlJvjlJeD8fjzxOvvN8zlfkvPlMc3dEREREpHFoke0CiIiIiEgphTMRERGRRkThTERERKQRUTgTERERaUQUzkREREQaEYUzERERkUYk0XBmZkPMbI6ZzTWzMVWcc4CZTTWzmWb2aibXioiIiDQ3ltQ8Z2aWA3wMHAwUAJOB4919VplzNgHeAoa4+5dmtoW7L6zJtSIiIiLNUZI1Z/2Bue4+z93XABOA4RXOOQF4zN2/BHD3hRlcKyIiItLsJBnOtgbml9kuSO0ra0dgUzN7xcymmNnJGVwrIiIi0uy0TPDelmZfxTbUlkA/4CCgLfC2mb1Tw2vjTcxGAaMA2rVr12/nnXeudYFFREREGsqUKVMWu3vHivuTDGcFwDZltrsAC9Kcs9jdVwIrzew1YLcaXguAu48DxgHk5eV5fn5+/ZReREREJEFm9kW6/Uk2a04GephZdzNrDRwHTKpwzr+Afc2spZltCPwE+KiG14qIiIg0O4nVnLl7oZmdAzwL5AB3u/tMMxudOj7W3T8ys2eA6UAxcKe7zwBId21SZRURERFpLBKbSiMb1KwpIiIiTYWZTXH3vIr7k+xzJiIiIk3c2rVrKSgoYPXq1dkuSpPVpk0bunTpQqtWrWp0vsKZiIiIVKmgoIDc3Fy6deuGWbrJFKQ67s6SJUsoKCige/fuNbpGa2uKiIhIlVavXk2HDh0UzGrJzOjQoUNGNY8KZyIiIlItBbO6yfT5KZyJiIhIo7Vs2TJuvfXWWl176KGHsmzZshqf/7vf/Y4//elPtXqv+qRwJiIiIo1WdeGsqKio2mufeuopNtlkkwRKlSyFsww89hg8+2y2SyEiIrL+GDNmDJ9++il9+/blN7/5Da+88gqDBg3ihBNOoHfv3gCMGDGCfv360atXL8aNG/ffa7t168bixYv5/PPP2WWXXfjlL39Jr169OOSQQ/jhhx+qfd+pU6ey11570adPH4488kiWLl0KwI033kjPnj3p06cPxx13HACvvvoqffv2pW/fvuy+++58//33dfvQ7t5sfvr16+dJ6tvXfdiwRN9CRESkUZk1a1ZW3/+zzz7zXr16/Xf75Zdf9g033NDnzZv3331Llixxd/dVq1Z5r169fPHixe7uvu222/qiRYv8s88+85ycHP/ggw/c3f2YY47x8ePHV3qvK6+80v/4xz+6u3vv3r39lVdecXf33/72t37eeee5u/uWW27pq1evdnf3pUuXurv74Ycf7m+88Ya7u3///fe+du3aSvdO9xyBfE+TZzSVRgbat4fvvst2KURERLLj/PNh6tT6vWffvvDXv2Z2Tf/+/ctNS3HjjTcyceJEAObPn88nn3xChw4dyl3TvXt3+vbtC0C/fv34/PPPq7z/8uXLWbZsGfvvvz8Ap5xyCscccwwAffr0YeTIkYwYMYIRI0YAMGDAAC688EJGjhzJUUcdRZcuXTL7QBWoWTMDCmciIiLZ165du//+/sorr/DCCy/w9ttvM23aNHbfffe001ZssMEG//09JyeHwsLCWr33k08+ydlnn82UKVPo168fhYWFjBkzhjvvvJMffviBvfbai9mzZ9fq3iVUc5aB3FyFMxERWX9lWsNVH3Jzc6vtw7V8+XI23XRTNtxwQ2bPns0777xT5/fceOON2XTTTXn99dfZd999GT9+PPvvvz/FxcXMnz+fQYMGMXDgQB544AFWrFjBkiVL6N27N7179+btt99m9uzZ7LzzzrV+f4WzDLRvD3Xt4yciIiI116FDBwYMGMCuu+7K0KFDOeyww8odHzJkCGPHjqVPnz7stNNO7LXXXvXyvvfccw+jR49m1apVbLfddvz973+nqKiIE088keXLl+PuXHDBBWyyySb89re/5eWXXyYnJ4eePXsydOjQOr23Fj7PwMUXw003wToGeIiIiDQbH330Ebvssku2i9HkpXuOVS18rj5nGcjNhdWrYe3abJdEREREmiuFswy0bx+vatoUERGRpCicZaAknGlQgIiIiCRF4SwDCmciIrI+ak7907Mh0+encJaB3Nx4VTgTEZH1RZs2bViyZIkCWi25O0uWLKFNmzY1vkZTaWRAfc5ERGR906VLFwoKCli0aFG2i9JktWnTJqNVAxTOMqBmTRERWd+0atWq3FJJkjw1a2ZA4UxERESSpnCWgZI+Z2rWFBERkaQonGVgo43iVTVnIiIikhSFswzk5ERAUzgTERGRpCQazsxsiJnNMbO5ZjYmzfEDzGy5mU1N/VxR5tjnZvZhan9yC2ZmKDdX4UxERESSk9hoTTPLAW4BDgYKgMlmNsndZ1U49XV3P7yK2wxy98VJlbE22rdXnzMRERFJTpI1Z/2Bue4+z93XABOA4Qm+X4No3141ZyIiIpKcJMPZ1sD8MtsFqX0V7W1m08zsaTPrVWa/A8+Z2RQzG5VgOTOicCYiIiJJSnISWkuzr+LaD+8D27r7CjM7FHgc6JE6NsDdF5jZFsDzZjbb3V+r9CYR3EYBdO3atd4KX5XcXFi4MPG3ERERkfVUkjVnBcA2Zba7AAvKnuDu37n7itTvTwGtzGzz1PaC1OtCYCLRTFqJu49z9zx3z+vYsWP9f4oKVHMmIiIiSUoynE0GephZdzNrDRwHTCp7gpl1NjNL/d4/VZ4lZtbOzHJT+9sBhwAzEixrjSmciYiISJISa9Z090IzOwd4FsgB7nb3mWY2OnV8LHA0cKaZFQI/AMe5u5tZJ2BiKre1BB5w92eSKmsmSsKZO1i6hlsRERGROkh04fNUU+VTFfaNLfP7zcDNaa6bB+yWZNlqKzcXiopg9Wpo2zbbpREREZHmRisEZEiLn4uIiEiSFM4ypHAmIiIiSVI4y1BubrxqlQARERFJgsJZhlRzJiIiIklSOMuQwpmIiIgkSeEsQwpnIiIikiSFswypz5mIiIgkSeEsQ6o5ExERkSQpnGWobVvIyVE4ExERkWQonGXILGrP1KwpIiIiSVA4q4XcXNWciYiISDIUzmqhZPFzERERkfqmcFYLCmciIiKSFIWzWsjNVZ8zERERSYbCWS2o5kxERESSonBWCwpnIiIikhSFs1rQVBoiIiKSFIWzWijpc1ZcnO2SiIiISHOjcFYLJUs4rViR3XKIiIhI86NwVgtaX1NERESSonBWCyXhTP3OREREpL4pnNVCbm68quZMRERE6pvCWS2oWVNERESSkmg4M7MhZjbHzOaa2Zg0xw8ws+VmNjX1c0VNr80mNWuKiIhIUlomdWMzywFuAQ4GCoDJZjbJ3WdVOPV1dz+8ltdmhZo1RUREJClJ1pz1B+a6+zx3XwNMAIY3wLWJU7OmiIiIJCXJcLY1ML/MdkFqX0V7m9k0M3vazHpleG1WqOZMREREkpJYsyZgafZ5he33gW3dfYWZHQo8DvSo4bXxJmajgFEAXbt2rXVhM9G6NbRpoz5nIiIiUv+SrDkrALYps90FWFD2BHf/zt1XpH5/CmhlZpvX5Noy9xjn7nnuntexY8f6LH+1cnNVcyYiIiL1L8lwNhnoYWbdzaw1cBwwqewJZtbZzCz1e/9UeZbU5Npsa99e4UxERETqX2LNmu5eaGbnAM8COcDd7j7TzEanjo8FjgbONLNC4AfgOHd3IO21SZW1Ntq3V7OmiIiI1D+LLNQ85OXleX5+foO81wEHxOsrrzTI24mIiEgzY2ZT3D2v4n6tEFBL6nMmIiIiSVA4qyX1ORMREZEkKJzVkvqciYiISBIUzmpJzZoiIiKSBIWzWmrfHlavhrVrs10SERERaU4UzmqpZH1NNW2KiIhIfVI4qyUtfi4iIiJJUDirJS1+LiIiIklQOKsl1ZyJiIhIEhTOakl9zkRERCQJCme1pJozERERSYLCWS2pz5mIiIgkQeGsltSsKSIiIklQOKuljTaKV9WciYiISH1SOKulFi1g441h4cJsl0RERESaE4WzOthzT3jzzWyXQkRERJoThbM6OPBAmD4dFi3KdklERESkuVA4q4MDD4zXV17JajFERESkGVE4q4N+/WJKjZdeynZJREREpLlQOKuDli1h//0VzkRERKT+KJzV0YEHwscfQ0FBtksiIiIizYHCWR2V9Dt7+eXslkNERESaB4WzOurdGzp0UNOmiIiI1A+Fszpq0QIGDYpw5p7t0oiIiEhTl2g4M7MhZjbHzOaa2ZhqztvTzIrM7Ogy+z43sw/NbKqZ5SdZzroaNAi+/BLmzct2SURERKSpSyycmVkOcAswFOgJHG9mPas473rg2TS3GeTufd09L6ly1oeSfmdq2hQREZG6SrLmrD8w193nufsaYAIwPM155wKPAk12lcqddoItt1Q4ExERkbpLMpxtDcwvs12Q2vdfZrY1cCQwNs31DjxnZlPMbFRipawHZlF7pn5nIiIiUldJhjNLs69idPkrcIm7F6U5d4C770E0i55tZvulfROzUWaWb2b5i7K4yOWBB8LChTBrVtaKICIiIs1AkuGsANimzHYXYEGFc/KACWb2OXA0cKuZjQBw9wWp14XARKKZtBJ3H+fuee6e17Fjx3r9AJko6Xf2xBNZK4KIiIg0A0mGs8lADzPrbmatgeOASWVPcPfu7t7N3bsBjwBnufvjZtbOzHIBzKwdcAgwI8Gy1lm3brDffnDrrVBYmO3SiIiISFOVWDhz90LgHGIU5kfAw+4+08xGm9nodVzeCXjDzKYB7wFPuvszSZW1vlxwQUypMXFitksiIiIiTZV5M+rBnpeX5/n52ZsSragIdtwROneGN9/MWjFERESkCTCzKemmC9MKAfUoJwd+/Wt46y14771sl0ZERESaIoWzevaLX0D79nDDDdkuiYiIiDRFCmf1LDcXzjgD/vlPKCjIdmlERESkqVE4S8C558ZktDffnO2SiIiISFOjcJaAbt3gyCNh3DhYuTLbpREREZGmROEsIRdcAEuXwvjx2S6JiIiINCUKZwnZZx/YfXe45RattykiIiI1p3CWEDM45xyYMQNeey3bpREREZGmQuEsQccfD5ttpoEBIiIiUnMKZwlq2xZOPz2Wc9K0GiIiIlITCmcJO/NMKC6GsWOzXRIRERFpChTOEta9OwwbFtNq/PhjtksjIiIijZ3CWQM45xxYtChWDRARERGpjsJZAzjoINhpJw0MEBERkXVTOGsALVrAWWfBu+/G1BoiIiIiVVE4ayBHHhmvzz2X3XKIiIhI46Zw1kC22SaaNl94IdslERERkcZM4awBDR4Mr74Ka9ZkuyQiIiLSWCmcNaDBg2HVKnjnnWyXRERERBorhbMGdMABMThATZsiIiJSFYWzBrTJJrDnngpnIiIiUjWFswY2eDC89x4sX57tkoiIiEhjpHDWwAYPhqKiGBggIiIiUlGi4czMhpjZHDOba2ZjqjlvTzMrMrOjM722qdl7b2jbVk2bIiIikl5i4czMcoBbgKFAT+B4M+tZxXnXA89mem1TtMEGsN9+CmciIiKSXpI1Z/2Bue4+z93XABOA4WnOOxd4FFhYi2ubpMGD4aOP4Kuvsl0SERERaWxqFM7M7Dwza2/hLjN738wOWcdlWwPzy2wXpPaVve/WwJHA2EyvbcoGD47XF1/MbjlERESk8alpzdkv3P074BCgI3AacN06rrE0+7zC9l+BS9y9qBbXxolmo8ws38zyFy1atI4iNQ59+sDmm6tpU0RERCprWcPzSsLSocDf3X2amaULUGUVANuU2e4CLKhwTh4wIXWrzYFDzaywhtcC4O7jgHEAeXl5aQNcY9OiBRx0EDz/PCxeHEFNREREBGpeczbFzJ4jwtmzZpYLFK/jmslADzPrbmatgeOASWVPcPfu7t7N3bsBjwBnufvjNbm2qTv5ZFi0CHbYAW64QettioiISKhpODsdGAPs6e6rgFZE02aV3L0QOIcYhfkR8LC7zzSz0WY2ujbX1rCsTcKhh8L06TG1xoUXwq67wuOPgzeJuj8RERFJinkN0oCZDQCmuvtKMzsR2AP4m7t/kXQBM5GXl+f5+fnZLkbGnn4a/ud/YgTnnnvC1VfDT38K62w4FhERkSbLzKa4e17F/TWtObsNWGVmuwEXA18A99Zj+dZrQ4dGLdpdd8HChbE9cGAs8yQiIiLrl5qGs0KPKrbhRI3Z34Dc5Iq1/mnZEn7xC/j4Y7jtNvj8czjsMFixItslExERkYZU03D2vZldCpwEPJmawb9VcsVaf7VuDaNHw2OPxUjOG2/MdolERESkIdU0nB0L/EjMd/YNMSHsHxMrlfCTn8CwYfDHP8KyZdkujYiIiDSUGoWzVCC7H9jYzA4HVru7+pwl7OqrI5j95S/ZLomIiIg0lJou3/Rz4D3gGODnwLtmdnSSBRPo2xeOPjrmQVu8ONulERERkYZQ02bNy4k5zk5x95OJhcl/m1yxpMRVV8HKlfCHP2S7JCIiItIQahrOWrj7wjLbSzK4VuqgZ08YORJuvhm+/jrbpREREZGk1TRgPWNmz5rZqWZ2KvAk8FRyxZKyrrwylne64opsl0RERESSVtMBAb8hFhfvA+wGjHP3S5IsmJTaYQe44AK48054+OFsl0ZERESSVKPlm5qKprp8U02sXQv77QczZ8KUKdCjR+mx4mJ4+WXo1Al69dKyTyIiIk1BrZZvMrPvzey7ND/fm9l3yRVXKmrVCh56KF5//nNYvTr2f/klHHIIDB4MvXvDllvCCSfAffdpEXUREZGmqGV1B91dSzQ1Il27wr33wuGHw3nnxUS1558fNWc33QQbbggvvggvvQQPPhg1aCNHZrvUIiIikgk1azZBl1xSOrXGAQfA3XdD9+6lx4uLYbvtYJdd4Omns1JEERERWYeqmjWrrTmTxun//T/4/vuYZuOss6BFhcbpFi3g+ONj6adFi6Bjx+yUU0RERDKnucqaoFat4NZb4ZxzKgezEiecAEVF8M9/NmzZREREpG4Uzpqp3r1h113hgQeyXRIRERHJhMJZM3bCCfDmm/D559kuiYiIiNSUwlkzdtxx8TphQnbLISIiIjWncNaMde8O++yjpk0REZGmROGsmTvhBPjww/ipynPPweWXl05sKyIiItmjcNbMHXMM5OTEpLTp/PADnHYa/N//waBB8M03lc9ZvRoKC5Mtp4iIiASFs2Zuiy3g4IOjaTPdfMO33w4LFsTEttOnw557wgcfxLEPP4TRo2HzzWHoUFizpmHLLiIisj5SOFsPnHQSfPEFjBtXfv/KlfD738NBB8F118XITjMYMCD6qvXpA/fcEzVqL7wAZ55ZOeC5w+uvK7iJiIjUl0TDmZkNMbM5ZjbXzMakOT7czKab2VQzyzezgWWOfW5mH5YcS7Kczd1xx8Xi6OedB9Omle6/+WZYuBCuuSa2+/aFyZOj9mzRolhhoKAA/v1v+O1vY5mokmWjIK494gjYb7+oeRMREZG6S2xtTTPLAT4GDgYKgMnA8e4+q8w5GwEr3d3NrA/wsLvvnDr2OZDn7otr+p7ry9qatbFwIey+O7RrB1OmxPqb3bvD3nvDk0+u+3r3WET9wQdj1YHcXDjlFFi2LGrYPvgAZs6EHXdM/KOIiIg0C9lYW7M/MNfd56UKMAEYDvw3nLn7ijLntwOazyrsjcwWW0SwGjQIRo2CnXeGpUvh6qtrdr1Z1Jx98UWMAF27Fnr1guefj3v36AEXXQSTJiX7OURERJq7JJs1twbml9kuSO0rx8yONLPZwJPAL8occuA5M5tiZqMSLOd6Y7/9oglzwoRYPP2oo6Bfv5pf36YNPP54XPPrX0cTaO/e0KlTTMXx739H37Syxo2L87/8sl4/ioiISLOVZLPmMcBP3f2M1PZJQH93P7eK8/cDrnD3wantrdx9gZltATwPnOvur6W5bhQwCqBr1679vvjii0Q+T3NRXAyHHhpzm02fHutv1ofVq6Fnz2g2/eCDWJD98stjoAHAiBEwcWL9vJeIiEhzUFWzZpI1ZwXANmW2uwALqjo5Fby2N7PNU9sLUq8LgYlEM2m668a5e56753Xs2LG+yt5stWgRIak+gxlErdof/gAzZsCtt0b/tOuug1/9KmrpHn88atZERESkeknWnLUkBgQcBHxFDAg4wd1nljlnB+DT1ICAPYB/EyFuQ6CFu39vZu2ImrOr3f2Z6t5TAwKyyx323z+m1oAIZxdfHBPY7r47rFgRgwbatSu95ocfYNUq6NAhO2UWERHJlgavOXP3QuAc4FngI2Ik5kwzG21mo1On/QyYYWZTgVuAYz3SYifgDTObBrwHPLmuYCbZZwY33gg77RST3l5ySexr1Qpuuy0GE5RM2wHwzDNx7vbbwzvvZK/cIiIijUliNWfZoJqzxu300+Hee+Hll+Guu+Af/4BddokJbL/9Fp56CvbdN/21c+bESNAXX4QLL4x529Zl5cp4r8MOi5AoIiLSmGSjz5lIOddfDxtvHAFs/Hi47DJ4/3147TXo0gWGDInwBdEU+vrr8JvfRO3azjtHE+nLL8MVV9Ts/f70Jxg2rLSZtTF77TXQvytERAQUzqQBbb453HFHrPX53ntw7bUxkGCrreCVV2C77aKW67jjoHPnmPrjb3+LyXJvuSWaRa+/Ht59t3T9z6q4w333xe+33pr4R6uTwsJYoP6ss7JdEhERaQzUrCmNxuLFMeXG7Nkx3ccRR0TzZfv2pecsXQpbbx3rhd5+e9X3evdd2Gsv6NYtlqCaPz8CX3WWL4/XjTeu6yfJzAsvRGBt2TJWXCg7YEJERJovNWtKo7f55vDGG7Gu5733wtFHlw9mAJtuGjVr998P331X9b3uuw822CCWmioshDvvrP69Z82KpaeGDq28uHvSJkyI18LCqFEUEZH1m8KZNDrr6rw/enR09i9ptqxo7doIPEccAXl5Uft2++0RftKZNSuWtfrPf+Dtt5MZObp4cdTmVbRmDTz6aJTVLMKpiIis3xTOpMnZc0/YYw8YOzZ9Lddzz0UYOvHE2D7rrGjafOKJyufOmgUHHhiT877zTjRp3nhj/Zd5zBgYMCCabCuWddmyCJy77qpwJiIiCmfSBJlFmPnwQ3jrrcrH778fNtssRn9CDDLo0qXywIAPP4xgZhajQPv1i+k+HnkEvvqq/spbVAT/+le8XnZZ+WMTJkRZBw+GgQPj81RVwyciIusHhTNpko4/PvqjjR1bfv/338dSUcceC61bx76WLWMZqeefh48/jpUKxowpXfT95Zdjqg6Ac86JEHXbbZmX6T//Sb//rbeiJq9//1g6qyRQrloVoe3oo2Oi3oEDo2wffpj5e4uISPOhcCZN0kYbxYjNhx+Gb74p3T9xYiwJVdKkWeKMMyKknXVWBLHrr4/1P6dNKw1mENN2HHFE9FFbvbrm5Xn8cejYEd58M/2x1q3jtXPnmK/NPSbdXbEiBjhAhDNQ06aIyPpO4UyarLPOilquHXeE88+HTz+NQQLdu8Pee5c/t3Nn+NnPYpLbTp2i9urvf4/fKzrvvKjpevDBmpWjqAguvxyKi2NetrLcI5QddBBsuSX87ncR4CZNiibNkvncALp2hW22UTgTEVnfKZxJk9WzZ4yAPOKImKS2R4+YM+zEE9OP+LzxxghK771XObyVdcAB0Tn/b3+r2bQaDz0UAwv69IHHHivfX23GDJg3L+Zvg+jTttNOsfLBk0/Cz38OOTml5w8cGOFsXe/71VcNP+WHiIg0DIUzadL69Yvasi++iNqr/v0jAKWzxRYwfHj5MJSOGfz619Hked99MHduTH5bXFz53MLCqA3r3TuCWXFx+X5wjz8e9zviiNhu2RJ+/3v45JNoNi1p0iwxcCAsWACff151+d54I2rYHn20+s8hIiJNk8KZNAtbbQXXXBPTYWy7bd3vN3JkTIp78slRI7fZZrHU1KWXlg9p990XQeuqq2D77eHww2HcOPjxxzj++OOxUkHZ1QlGjIhpNbbbLo6VVZN+Z1deGbVm99xT98+ZTroQKiIiDUfhTCSNDTeEKVOi0/6998Jf/hJ91q67Dk44IWq91q6Fq6+OOddKmi3POQcWLozpOL78MhZ2LzlWwizmXHvjjcrNr716xVxr6QYWQCyQ/tJLUXP2zDOwZEn9fu6lS2GXXaI2UEREsqNltgsg0lh17Ro/JdwjiF18cfT5Ouww+OwzuOmm0pA1eHAMULj55tKpNSqGM4BNNomfinJyYJ99qq45+93vohbuwQejlu3RR2HUqNp/xoouuiimG/n97+G00+qnFlJERDKjmjORGjKLjvwTJsSggksvhZ/8JBZpL9GiBZx9djSv/vnPUQu1446Zvc/AgTBzZuV50159NeZku+SSCHA77VTzEaU18eKLcPfdcMop8TmuuKL+7l1bs2dHDaWIyPpE4UwkQ8ceG0Fmjz2iubNi0+Qpp0C7djFIIV2t2boMGBCvFVc/uOqqqDX71a/iPY8/PgLbulYzKCyMsPf00zF/2+WXR7+4oqLSc1auhF/+MvrX3XZbDIgYPx6mT8+8/PXlnXdiRG4Sy2mJiDRmCmcitTBwYPRJ22efysc23jgGEkCMDs1U//6xYsDll0d/t5Ury9eatW0b5x1/fDS1Pvxw+vssWBB94rp1i6lBDj00lr267roIePvsU7oawRVXRBPtnXfG/ceMic9x6aWZl7867jWbAsQdLrwwXsePr98yiIg0dgpnIgm4+uoIOv37Z35t27Zw112xvNMpp8TktSefXFprVmLHHaP2rmLT5ty5sSRU164xsrNXrxjZ+eabsQD8mjVxzbx5cf3o0fDXv8ZryYS4m24aweyppyIYlvj++1gGa+XK9GX/6qtYzD0d9/g8hxxSOpq1Ko88Am+/HfPRTZsWNX8iIusNd282P/369XOR5qK42P3VV91PPtm9XTv322+vfM4f/xh1UZ98Etvvvuu++ebuG2/sftFFpfvTWbTI/cQT4/ouXdyXLy9/fNUq9623dv/JT9zfeMP9tNOiHOC+5Zbud9zhXlgY565Y4X7FFe5t28bxhx+u/H4PPVRSb+Z+9tlVl2v1avfu3d379HH/6iv3Fi3cL7us2kclItIkAfmeJs+YN6NpxvPy8jw/Pz/bxRBpMPPnRw3ZNdfA7rvHigOdO8c0Gz161Ower78e64KWXWO0xF13xbqkEOuZHnssHHxwrJ7w9ttRKzdyZIxY/frrOP7pp1F7N316TPkBMeVHz55R1n33hRtuiDniRo6s/J5//nOMGn3uuXivn/40RpDOm5d+5YeaWrEiomFubu3vISJSn8xsirvnVdqvcCbStO23XywftWwZ9O0by0KlWzO0NgoLo2l0++0j+G20Uex3jxURxoyJIPaTn0Tg2nvv2O7bF/LyYuBETk5My3HffZCfH4HuoINg8uRYfqt379L3W7IEdtgh7vPUU7Hv3nujOfStt6pfdmtdhg+Pedxee6329xARqU8KZyLN1NixcOaZUcP0yCOlAaohrFkDc+ZE4GpRpgfr3/8Ov/hFzJfWr1/0M7vsMrj22jj+9dfR3y03NwLcqlUxee+4cfDAA1Hr1qtXnPvddxE2zzgjauhqwz360S1fHgMlttyybp9bRKQ+KJyJNFOFhTFNxpAhMcqzMXCPJs6JE2NN0402io79bdqUnvP66zBoUPkpPQDOPbfy9Bk//zm88koMOKjNZ5w7t7SZd9y4mDZERCTbqgpniY7WNLMhZjbHzOaa2Zg0x4eb2XQzm2pm+WY2sKbXikho2RKGDWs8wQyib9jtt0cN1YIFcMcd5YMZRN+z55+PueLuuy/6mE2bFv3ZKjrhBFi0KGrZamPy5Hht2xYmTardPUREGkpiyzeZWQ5wC3AwUABMNrNJ7j6rzGkvApPc3c2sD/AwsHMNrxWRRmzTTSNwffRR6RQdFQ0aFD/rMnRoLHf1wANRQ5ip/PwIh6eeGk2uq1bF+qkiIo1RkjVn/YG57j7P3dcAE4ByU3K6+wovbVdtB3hNrxWRxm/nneHII+t+nw02iLnbJk6MYJWpyZNjNOvPfhaL1r/wQuVzZs+OueBmzIhRsCtW1L3cIiK1kWQ42xqYX2a7ILWvHDM70sxmA08Cv8jkWhFZf5x0UgSm00/PbL3NoiJ4//0YPbrvvtC+feWmzU8/hd12i5UfeveOKT/at48pSUREGlqS4SzdjESVRh+4+0R33xkYAVyTybUAZjYq1V8tf9GiRbUtq4g0cvvtF0tPTZgQa5bWtAZtzpxY0SAvD1q3jibSJ56A4uLScy6+OPrsTZwIDz0Et94agxqmTUvko4iIVCvJcFYAbFNmuwuwoKqT3f01YHsz2zyTa919nLvnuXtex44d615qEWm0LrkkRls+/XRMHbJs2bqvKRkMsOee8TpsGHz7ben+V18tnbNtxIgYGXrmmdEn7dtvk/gUIiLVSzKcTQZ6mFl3M2sNHAeUa0wwsx3MYs5vM9sDaA0sqcm1IrJ++uUvo/bs3XdjDrWBA2P1gc6dY260H34of35+fkzlseOOsT10aEyMO2lS1J5deCF06RKvZXXqpHAmItmR2GhNdy80s3OAZ4Ec4G53n2lmo1PHxwI/A042s7XAD8CxqQECaa9Nqqwi0rT8/OcxevOqq6KpslevCFwPPQT//GcsFF8iPz9CXE5ObG+2WfQ9+/e/I7C9/35M5VFx9KbCmYhkiyahFZFmwT1Gh3bsCG+8EfvWro2O/WefDX/6U+m5f/kL/M//QIcOsTTV22+XX+EAoonz00/hww8b7COIyHomK5PQiog0FDMYNSqmw5iZqmefOTOmzsir8FffsGHxumRJrAlaMZhBNJOq5kxEskHhTESajVNOiWbOO+6I7ZKK9JLBACV69IjF2k89FfbZJ/29OnWCxYtjeSwRkYakcCYizcbmm8NRR8E998TAgMmTo2/adttVPvett+Cuu6q+V6dO0VSqGXpEpKEpnIlIszJqVEyx8cgjUXOWlxdNnhW1aJG+ObNEp07xqqZNEWloCmci0qwccEA0W950U3Tmr9ikWVMKZyKSLQpnItKslAwMmDw5RmtWHAxQUwpnIpItCmci0uycckosxwSqORORpkfhTESanY4dY6Larl1j9v/ayM2Ftm0VzkSk4SW2QoCISDbdfjt8/336wQA1YaZVAkQkOxTORKRZatcufupC4UxEskHNmiIiVejUCb75JtulEJH1jcKZiEgVVHMmItmgcCYiUoWSJZyKirJdEhFZnyiciYhUoVMnKC6OgCYi0lAUzkREqqC5zkQkGxTORESq0LlzvCqciUhDUjgTEamCas5EJBsUzkREqqBwJiLZoHAmIlKF9u1hgw0015mINCyFMxGRKmgJJxHJBoUzEZFqKJyJSENTOBMRqYbCmYg0NIUzEZFqKJyJSENLNJyZ2RAzm2Nmc81sTJrjI81seurnLTPbrcyxz83sQzObamb5SZZTRKQqnTvDokWxUoCISENomdSNzSwHuAU4GCgAJpvZJHefVea0z4D93X2pmQ0FxgE/KXN8kLtr4RQRyZpOnWJtzSVLoGPHbJdGRNYHSdac9Qfmuvs8d18DTACGlz3B3d9y96WpzXeALgmWR0QkY5rrTEQaWpLhbGtgfpntgtS+qpwOPF1m24HnzGyKmY1KoHwiIuukcCYiDS2xZk3A0uzztCeaDSLC2cAyuwe4+wIz2wJ43sxmu/traa4dBYwC6Nq1a91LLSJSRkk400S0ItJQkqw5KwC2KbPdBVhQ8SQz6wPcCQx39yUl+919Qep1ITCRaCatxN3HuXueu+d1VIcQEalnqjkTkYaWZDibDPQws+5m1ho4DphU9gQz6wo8Bpzk7h+X2d/OzHJLfgcOAWYkWFYRkbQ22QRat2464ay4GH74oerjN9wAzzzTcOURkcwl1qzp7oVmdg7wLJAD3O3uM81sdOr4WOAKoANwq5kBFLp7HtAJmJja1xJ4wN3114mINDgz2GKLphHO5s+HYcNg7VqYPh1ycsofnzMHLrwQ2rSBt96C3XfPTjlFpHpJ9jnD3Z8Cnqqwb2yZ388Azkhz3Txgt4r7RUSyoXPnuoWzggJwh222Wfe5tTV5MhxxBCxeDIWF8K9/wVFHlT/nttugVSvYbDP42c8gPz9+bw7efx9WrID99st2SUTqTisEiIisQ11XCTj2WBgyJAJaptzhww+rv/bRR2H//aNGbMoU6NYtmi/LWrkS/vEPOProOL+gAEaOjDncMvH995l+guStWhU1hsceW7tnLNLYKJyJiKxDXcLZDz/Ae+/BrFnw5puZX3/jjdCnD1x6afrjN90UgWu33eDdd+PcX/8a3ngjasZKPPggLF8OZ58Ne+0V933mGbjqqpqX5ZZboon3gw8y/xxJuuEGWLAgRtTOUO9kaQYUzkRE1qFTJ1i4sHZLOE2ZEs2MAOPGZXbtZ5/BZZfBppvC9dfDzTeXP37TTRHERoyAl16K4ARw+umQm1tae+YewapPH9hnn9j3q1/BaafBNdfAE0+suyxr18J118Hq1XFtpjVumXr3XejfH/73f2Hu3KrPW7gwns3ee8f2c8+t+95ffw3du8ezW7u2fsrbFKxaFZ951qx1nytZ5u7N5qdfv34uIlLf/vpXd3BftCjza//wh7j2Zz9zb9PG/T//qdl1xcXugwe75+a6f/aZ+xFHuJu5P/poHL/llrjv8OHuP/5Y+frzz3dv2dK9oMD9rbfi3LFjy5+zapV7377uHTq4f/VV9eW57764x0knxeutt9bsc1SlqMj9H/9w/+KLyscWL3bfZhv3jTd2b9Ei3m/ffd3Hj4/nUtbZZ7vn5LjPnu2+887uP/3put/7jDNK7ztwoPvXX9ftszQVf/pTfOY994znL9kH5HuaPJP1QFWfPwpnIpKEBx+Mvy1nzMj82hEj3Lff3v2DD+IeN95Y/vjSpRE8LrzQfeXK0v13310+BK1c6b7XXu4bbBDBC9yHDUsfzNzd582LADJmjPvIke7t27t//33l8z76yL1t2wiCVX1hFxdHiNtllzjnwAMjOJUNNcuWuR97rPtBB7kvWVL9Mykudj/rrPgMXbq4f/xx6bGiIvfDDnNv3do9Pz/C5e9/777jjqVhtCTgzpkTAfTMM2P73HPjs/zwQ9XvPX16PJcLLnB/4IE4f6utIsA2ZytWuHfs6N65czzHceOyXSJxVzgTEam1116Lvy0ffDCz64qL3Tt1itom96ix2HXX0tqf4mL3Y44prcXp0cP9zTcj9GyySYS2soFp0aI4ByLArF5d/fsfdVTcp3XrCC5VGTcu7vmHP6Q//sILcfzOO2N79uy45wknxPaMGRGecnJif69eVdfEFRe7/+Y3cb9TTnHffHP3LbeMkOheWtN4882Vr/vrXyOMde8ewe3II9032sj9m2/inEmT4toXX6z6sx5yiPumm5YGyGnT3Lfbzr1VK/fbb6/6uqbu+uvj2bz1lvt++7lvtlnUUDZWM2a4P/FEtkuRPIUzEZFaWrs2wseuu7oXFlY+/uij0exY8di8eeVrv0pCUEktzR13xPZ110Wg2HbbaLrs0SNqyObMqfxeX3wRzVPV1Q6VeP31uD+4z5pV9XnFxRHkWrZ0nzy58vEhQyJkln3PK66I+158sXu7dnH8tdfic2y0UQSoTz+tfK/f/S6uO+useN8ZM+LaTp0i/OXkuB99dOXmyxJvvx1Nnq1axX2uuab02HffxWe45JL01z79dFzzl7+U379kSXxGiCbPmjzbst5/3/3aa90vvdT91792P/109xtuiFrRdBq6SfG776LpesiQ2J4+PZ7zr37VsOWoiR9/jD8jrVrF/wtVPcPmQuFMRKQOHnoo/sYcP778/m++iZoYiBqmskr6aX3wQWx/910El1NPdZ85s3Jz4nffuY8eHddcf33dy1xcHH2qhg5d97lLlkQTY48epTVR7u4fflg5BLlHgNlhhzg2YED5mrJ3342amS23jObZO++MmrCzz47zTz21fED56KM4F6IJeNmy6su6eHGE4Z13Lt8U7B61jXvsUfmatWujRm/77dM3BRcWul9+eZShf3/3+fOrL0OJoqLS2sycnGju7dQptjfcMALQ9Onu773nfvXV7vvsE30PL7us6gCaiaKiqpu2S1x7bZTn3XdL951/foSfdGE8W95/33233aKse+0Vr8891/DlKC6uXf/S2lA4ExGpg6Ki6He13XblvwyPPTaa8kpCV1lnnx37164t3TdqVISyXr2iD9CCBZXf65tv6ueL2z2aPtf15V3ilVei5qlNmwiJn3ziftppUd50TWBTp0YtXrr7z5zpvvXW/t+au5Kfk05KX/v48cfRTDl1as0/W7pndPXVEToqfrmW1Fo+8kj195w4MQZhbLhhhKxNNonP361b+lqcZ54pDe1ly/P++/HsNtig9LObRdP20KGxXdeA9uKL8edxgw3cBw1y/3//L2pl16wpPWfZsvjHw+GHl7922bL4fP37N47BAQ89FH/2Ond2/9e/3Jcvj+d11VUNW47iYvdzzon/3g3R7KtwJiJSR0895eWaKf/9b/9vrdJpp8WX+qpVpefvsUd0ni8rP7/0y/rJJxuu7DU1e3Y07bVuHV+OOTkRMmtjxYpomv3iC/eFC9MPSKhv77wTz3bChNJ9BQURhAcMqFkY+uijCKejRkVfvXPPjXv+7neVzx02zH2LLaru/7dokftNN7nff388A/cIQ6NGxT3/93/XXaaKYXbZstLrd9jB/bzz4h8OJX+uNtoo+iT++c+ltZVTplS+7/jxcWzoUPdvv13nY6mTzz+PMt5zT+Vj06ZFAB4woPxgkl13rVmt79q10RT+f/9XtzKW/e9y4YX19w+k6iiciYjUUUkz4ZZbRu1Wly7xBfLjj1GLAVED4B7BJCcnmsoqOvHEun+RJG3BguhD1a9fTOXRVBQWRm3X6afH9urV0US20UZRm1dbI0ZEk2XZ2rPPPosAm+6/8boUFUUIBvcrr6z6vLvuivfo3Dk+x7HHRo1kixYxsKLsPwYWLXL/5z9j9GrJ6NaSEa7pFBfHlCwbbBB/pqsbSFEXxcXuhx7q/609LBvQliyJ2r+ttqo8pckZZ0St37pCUskgEqj9oI7Cwqj5hvhz3xDBzF3hTESkXpSM3OzWLb5o3nkn9hcWxhfMsGGx/fLLcd76MOKssTnqqBg0UFxcWhOyrubMdXn//bhP2Wa2Sy6JkPTll7W7Z1FR1LhWN8L08MMjmJ1+ekxTsv320RT53nvrvv/8+fGPhbJ9CNOZOtV9p53iz/Oll6bv87d8eQxcufbadb9vRSX9Na+9NvpYmrnfe2/8PzNkSHT+TzeVyZ13xnWzZ1d9748/jmb44cMjAObkRA13dV54wX3vvSNwX355jMIeObI0KDdUMHNXOBMRqTclfYYqTk9x0UXRb2bRoqgZg8Y9XUFzddtt8exLpuwYM6Z+7nvEEVErt2xZDIjo0CG+4Oti5cpoQr7oosrHCgujtu6MM+r2HjWxYkVpUGzXrnQgw9KlEUhLBr1kGnSXLo1wucce0fy4cmWETLPSEbIVJ0cuMWNGHP/HP9IfLypy33//eEZffRXN5rvvHrWkJYNwKnrooQiD3brFgJKcnNLPVZvgWVcKZyIi9eSTT2LKhO++K79/6lT/b5+0ww+P2ghpeJ9+WvqFe/DB6Qcg1EZJf8FrrommOXB//vm633f//SNUVFRSW1dxhHCS8vMjpLVpE+/dtm28HnFETGOyxx7Rx67igIvi4qjpuv/+8gMSfvWrqF0s2+dt5croi1kydUlVNVVFRTF58ujR6Y/ffnvc4447Svd99VXUmm61lftLL5Uvy003RSjcd9/S5unVq6PPW7o+eQ1B4UxEJGHFxTEKc599YnLViqM3peHsuGMyI+4OPzxqkfr2jfBdH01gV10VoaFiWUuWDatts2ldLF4cfblGjSpfCzVtWtQ8lUxA7B7P4KKLSgNx165R9mefje0LLqh8/5UrozlxXRMpH3xwPOuKCgoiuA0aVPm/wfTppTV97dtHM3dJ/77hw8v308s2hTMRkQbw+9+XfklpiZzs+fTT9NOU1NXkyaX/ff/2t/q55xtveNrmwiOPjMl8G5uSiYQffzxqt0qW4jr77FilYd99ywe1uozS/e1vo+at4j2OPjpq9ebOTX/d8uUxOfQZZ5RO6XL66eWntWkMqgpnFseah7y8PM/Pz892MURkPfbFF9CtW/z+4Yew665ZLY4k4PDD4dVXoaAANt647vdbuxY22wxOOgluvTX2FRfDFlvAsGHw97/X/T3q05o10L8/fPstHHwwjB8PF10Ef/gDmMU5b78Nd9wBp50G++5b+/d6+mk49FB4+WU44IDYN3067LYbXHEFXHXVuu/hDkuWwOab174cSTGzKe6eV3F/i2wURkSkudp2W9hvv/jS7tkz26WRJIwfD/n59RPMAFq1ij8zL75Yum/WrAgU++9fP+9Rn1q3jsC4eHE8iyuvLB/MAPbeG+6+u27BDCIEArzzTum+//s/yM2F886r2T3MGmcwq07LbBdARKS5uf12WLAAWuifv83SppvGT3066CB46qmojevSJWrmoHGGM4Ddd4d77oEff4zasaR06AA77hg1cQBz5sDDD8PFF0dtY3OlcCYiUs923jl+RGrqoIPi9aWX4OSTI5xts01pE3ljdMIJDfM+e+0FzzwTzZPXXQdt2sCFFzbMe2eL/l0nIiKSZb17R9Pbiy9GCHn11ag1K9tUuL7ae29YuBBeeSWaUUeNiv54zZnCmYiISJa1aAGDBkU4mzMnwkhjbdJsaHvtFa+nnhrP6aKLslqcBqFwJiIi0ggcdBB89VWMcoQYJCAx4nnDDeHLL6N/W5cu2S5R8hTOREREGoGSfme33gqdO0OPHtktT2PRsiXsuSfk5MAll2S7NA0j0XBmZkPMbI6ZzTWzMWmOjzSz6amft8xst5peKyIi0pxsvz107QqrV6u/WUVXXQV33gnbbZftkjSMxMKZmeUAtwBDgZ7A8WZWcdafz4D93b0PcA0wLoNrRUREmg0zOPDA+F39zcrbf//oc7a+SLLmrD8w193nufsaYAIwvOwJ7v6Wuy9Nbb4DdKnptSIiIs3NsGHRfDd4cLZLItmUZDjbGphfZrsgta8qpwNP1/JaERGRJu/II2MiWvU3W78lOQltutbytAt5mtkgIpwNrMW1o4BRAF27ds28lCIiIo2EWQwGkPVbkjVnBcA2Zba7AAsqnmRmfYA7geHuviSTawHcfZy757l7XseOHeul4CIiIiLZkmQ4mwz0MLPuZtYaOA6YVPYEM+sKPAac5O4fZ3KtiIiISHOUWLOmuxea2TnAs0AOcLe7zzSz0anjY4ErgA7ArRZjhgtTtWBpr02qrCIiIiKNhbmn7crVJOXl5Xl+fn62iyEiIiKyTmY2xd3zKu7XCgEiIiIijYjCmYiIiEgjonAmIiIi0ogonImIiIg0IgpnIiIiIo2IwpmIiIhII9KsptIws0XAFwm/zebA4oTfo7nRM6sdPbfM6ZnVjp5b5vTMakfPrbxt3b3S8kbNKpw1BDPLTzcniVRNz6x29Nwyp2dWO3pumdMzqx09t5pRs6aIiIhII6JwJiIiItKIKJxlbly2C9AE6ZnVjp5b5vTMakfPLXN6ZrWj51YD6nMmIiIi0oio5kxERESkEVE4qyEzG2Jmc8xsrpmNyXZ5Gisz28bMXjazj8xsppmdl9q/mZk9b2afpF43zXZZGxszyzGzD8zsidS2ntk6mNkmZvaImc1O/ZnbW8+temZ2Qer/zRlm9qCZtdEzq8zM7jazhWY2o8y+Kp+TmV2a+n6YY2Y/zU6ps6uKZ/bH1P+f081sopltUubYev/MqqJwVgNmlgPcAgwFegLHm1nP7Jaq0SoE/sfddwH2As5OPasxwIvu3gN4MbUt5Z0HfFRmW89s3f4GPOPuOwO7Ec9Pz60KZrY18Gsgz913BXKA49AzS+cfwJAK+9I+p9TfcccBvVLX3Jr63ljf/IPKz+x5YFd37wN8DFwKembronBWM/2Bue4+z93XABOA4VkuU6Pk7l+7+/up378nviy3Jp7XPanT7gFGZKWAjZSZdQEOA+4ss1vPrBpm1h7YD7gLwN3XuPsy9NzWpSXQ1sxaAhsCC9Azq8TdXwP+U2F3Vc9pODDB3X9098+AucT3xnol3TNz9+fcvTC1+Q7QJfW7nlk1FM5qZmtgfpntgtQ+qYaZdQN2B94FOrn71xABDtgii0VrjP4KXAwUl9mnZ1a97YBFwN9TzcF3mlk79Nyq5O5fAX8CvgS+Bpa7+3PomdVUVc9J3xE18wvg6dTvembVUDirGUuzT8Ncq2FmGwGPAue7+3fZLk9jZmaHAwvdfUq2y9LEtAT2AG5z992Blag5rlqpPlLDge7AVkA7Mzsxu6VqFvQdsQ5mdjnR7eX+kl1pTtMzS1E4q5kCYJsy212IpgBJw8xaEcHsfnd/LLX7WzPbMnV8S2BhtsrXCA0AjjCzz4km8wPN7D70zNalAChw93dT248QYU3PrWqDgc/cfZG7rwUeA/ZBz6ymqnpO+o6ohpmdAhwOjPTS+bv0zKqhcFYzk4EeZtbdzFoTnRgnZblMjZKZGdEH6CN3/0uZQ5OAU1K/nwL8q6HL1li5+6Xu3sXduxF/tl5y9xPRM6uWu38DzDeznVK7DgJmoedWnS+Bvcxsw9T/qwcR/UL1zGqmquc0CTjOzDYws+5AD+C9LJSv0TGzIcAlwBHuvqrMIT2zamgS2hoys0OJfkE5wN3ufm12S9Q4mdlA4HXgQ0r7T11G9Dt7GOhKfEEc4+4VO9uu98zsAOAidz/czDqgZ1YtM+tLDKJoDcwDTiP+0annVgUzuwo4lmhi+gA4A9gIPbNyzOxB4ABgc+Bb4Ergcap4Tqlmu18Qz/V8d3+68l2btyqe2aXABsCS1GnvuPvo1Pnr/TOrisKZiIiISCOiZk0RERGRRkThTERERKQRUTgTERERaUQUzkREREQaEYUzERERkUZE4UxEpI7M7AAzeyLb5RCR5kHhTERERKQRUTgTkfWGmZ1oZu+Z2VQzu93McsxshZn92czeN7MXzaxj6ty+ZvaOmU03s4mpdSkxsx3M7AUzm5a6ZvvU7Tcys0fMbLaZ3Z+agV9EJGMKZyKyXjCzXYiZ8Qe4e1+gCBgJtAPed/c9gFeJWc0B7gUucfc+xIoXJfvvB25x992IdSm/Tu3fHTgf6AlsR6yZKiKSsZbZLoCISAM5COgHTE5VarUlFq4uBh5KnXMf8JiZbQxs4u6vpvbfA/zTzHKBrd19IoC7rwZI3e89dy9IbU8FugFvJP6pRKTZUTgTkfWFAfe4+6Xldpr9tsJ51a1pV11T5Y9lfi9Cf7+KSC2pWVNE1hcvAkeb2RYAZraZmW1L/D14dOqcE4A33H05sNTM9k3tPwl41d2/AwrMbETqHhuY2YYN+SFEpPnTv+xEZL3g7rPM7H+B58ysBbAWOBtYCfQysynAcqJfGsApwNhU+JoHnJbafxJwu5ldnbrHMQ34MURkPWDu1dXgi4g0b2a2wt03ynY5RERKqFlTREREpBFRzZmIiIhII6KaMxEREZFGROFMREREpBFROBMRERFpRBTORERERBoRhTMRERGRRkThTERERKQR+f85yETB+DRn7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAE9CAYAAAAmvEclAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgHElEQVR4nO3de3SU9b3v8c83dyAgAYJgiEIv4gUlYGjp9ohoz0K3RbyAR7qtArWoy8syax0tLbVHz9aueuqydXu0Kq2XYmktB8S2dm8oUCF6NrYSBbXFqsdLCagEUAQ1ksv3/DFDzGWSDMnvmZlk3q+1ZjHzzHP5PfySmU9+z+Vr7i4AAACEkZPuBgAAAPQnhCsAAICACFcAAAABEa4AAAACIlwBAAAERLgCAAAIKC/dDWhtxIgRPnbs2HQ3AwAAoFs1NTW73b20/fSMCldjx47V5s2b090MAACAbpnZ24mmc1gQAAAgIMIVAABAQIQrAACAgDLqnKtEGhoaVFtbq/r6+nQ3BRmoqKhIY8aMUX5+frqbAgCApD4QrmprazV48GCNHTtWZpbu5iCDuLv27Nmj2tpajRs3Lt3NAQBAUh84LFhfX6/hw4cTrNCBmWn48OGMagIAMkrGhytJBCt0ip8NAECm6RPhqq8pLi4+rOkAAKD/IFwBAAAERLjqxqJFi/TTn/605fUtt9yiO++8UwcOHNBXv/pVTZ48WSeddJJ++9vfJr1Od9eNN96oCRMm6KSTTtJvfvMbSdI777yjadOmqaKiQhMmTNDTTz+tpqYmzZ8/v2Xen/zkJ8H3EQCAvsy9SZ9+ukMffvhn1dWt1DvvPJjW9mT81YLpNnfuXFVVVenqq6+WJC1fvlyrV69WUVGRVq1apSFDhmj37t2aOnWqZs2aldQ5QI8//ri2bNmirVu3avfu3ZoyZYqmTZumX/3qVzrrrLP0ve99T01NTfr444+1ZcsW7dixQy+//LIk6YMPPohydwEAyCjNzY06ePAdffppbavH9navd0pqalnGLF+jRi2QWXrGkPpUuHrttSodOLAl6DqLiyv0xS/e1en7kyZN0q5du7Rz507V1dWppKRERx99tBoaGrR48WJVV1crJydHO3bs0HvvvadRo0Z1u81nnnlGX//615Wbm6sjjzxSp59+up577jlNmTJF3/zmN9XQ0KDzzz9fFRUV+tznPqc33nhD1113nb72ta9pxowZAfceAID0aW5u0MGDO/Xpp7Wqr28fmGIh6uDBdyU1t1kuJ2eACgvLVVg4RkOHntHyvPVDSt8FT30qXKXLnDlztGLFCr377ruaO3euJGnZsmWqq6tTTU2N8vPzNXbs2KRvCeDuCadPmzZN1dXV+sMf/qBLL71UN954oy677DJt3bpVa9as0b333qvly5froYceCrZvAABEobn5U3366Y4EgemzkaeDB9+T1PY7MSdnkIqKylVYWK5Bg87qEJoKC8uVlzc0o68W71PhqqsRpijNnTtXCxcu1O7du7Vx40ZJ0r59+zRy5Ejl5+frqaee0ttvJyyMndC0adP0wAMPaN68edq7d6+qq6t1xx136O2331ZZWZkWLlyojz76SM8//7zOOeccFRQUaPbs2fr85z+v+fPnR7SXAAAkp6npkwTBqe3IU0PDrg7L5eYOaRllGjRoYktgioWp2PPc3CEZHZyS0afCVbqceOKJ2r9/v8rKyjR69GhJ0iWXXKJzzz1XlZWVqqio0HHHHZf0+i644AJt2rRJEydOlJnpRz/6kUaNGqVf/OIXuuOOO5Sfn6/i4mItXbpUO3bs0IIFC9TcHBsS/eEPfxjJPgIAIElNTR+1Ck4dD9XV129XY+OeDsvl5ZW0BKTBg09JcKiuTHl5Q9KwR6lnnR2iSofKykrfvHlzm2nbtm3T8ccfn6YWoS/gZwQAktPYeCBhYGo9rbHx/Q7L5eUN7zDC1PowXWFhmXJzB6Vhj9LLzGrcvbL9dEauAADo49xdTU0fJhxlav26qWlfh2Xz80fGg9M4HXHEaa0C02cjTrm5A9KwV30X4QoAgAzm7mps/KCL2xDEpjU1HWi3pKmg4EgVFo7RwIFfVEnJmR1GnQoKjlJublFa9qs/I1wBAJAmseC0t9PbEBx63tz8cbslTQUFo1VYWK6BA09QScmMNqGpqKhcBQWjlZNTkJb9ynaEKwAAIuDerIaG3d3c/LJWzc3tb+OTq8LCo1RYOEbFxRM1fPjXOhyqKygYpZyc/LTsF7pHuAIA4DC5N+vgwV1dHKaLPdwPtlnOLE8FBWXx4HSKRow4P8GhulEyy03TniEEwhUAAK24N+ngwfc6vQ1B7OaXO+Te2GY5swIVFpapsLBcQ4ZMTXBF3RgVFIxMW0kWpA7hKos9/fTTuuqqq5Sfn69NmzZpwICeXw1SXFysAwfan0zZ1i233KLi4mLdcMMNnc7zxBNP6Nhjj9UJJ5zQ47YAQGd6UqdOknJyilqC0tChia6oG6P8/BEEJ0giXGWUxsZG5eWlrkuWLVumG264QQsWLEjZNrvzxBNPaObMmYQrAIet+zp1tTp48B11Xaeu4xV1seA0vM/fNRypQ7hKwvnnn6/t27ervr5e119/va644gpJ0urVq7V48WI1NTVpxIgRWr9+vQ4cOKDrrrtOmzdvlpnp5ptv1uzZs9uM7KxYsUJPPvmkHnnkEc2fP1/Dhg3TCy+8oMmTJ+viiy9WVVWVPvnkEw0YMEAPP/ywxo8fr6amJi1atEhr1qyRmWnhwoU64YQTdM8992jVqlWSpLVr1+q+++7T448/3qb969ev1w033KDGxkZNmTJF9913nx599FEtX75ca9as0bp167Rs2bKW+RctWqRjjjlGV199taTYiNPgwYN15ZVX6rzzztP777+vhoYG3XbbbTrvvPO6/L/7wQ9+oKVLl6q8vFylpaU65ZRTJEk/+9nPtGTJEh08eFBf+MIX9Oijj2rLli363e9+p40bN+q2227TypUr9ac//anDfAMHDgzTsQD6jJ7WqcvNLW5VbmVGwkN1mV6nDn0P4SoJDz30kIYNG6ZPPvlEU6ZM0ezZs9Xc3KyFCxequrpa48aN0969eyVJt956q4444gi99NJLkqT33+94p9v2Xn31Va1bt065ubn68MMPVV1drby8PK1bt06LFy/WypUrtWTJEr355pt64YUXlJeXp71796qkpETXXHON6urqVFpaqocffrjDKFR9fb3mz5+v9evX69hjj9Vll12m++67T1VVVXrmmWc0c+ZMzZkzp80yc+fOVVVVVUu4Wr58uVavXq2ioiKtWrVKQ4YM0e7duzV16lTNmjWr0w+lmpoaPfbYY3rhhRfU2NioyZMnt4SrCy+8UAsXLpQk3XTTTXrwwQd13XXXadasWW3aNHTo0ITzAeg/el6n7oiWoHSoTl37O4j3hzp16Hv6VLiqWl2lLe9uCbrOilEVuuvsu7qc5+67724ZHdq+fbtee+011dXVadq0aRo3bpwkadiwYZKkdevW6bHHHmtZtqSkpNs2XHTRRcrNjV0Zsm/fPs2bN0+vvfaazEwNDQ0t673qqqtaDhse2t6ll16qX/7yl1qwYIE2bdqkpUuXtln33//+d40bN07HHnusJGnevHm69957VVVV1Wl7Jk2apF27dmnnzp2qq6tTSUmJjj76aDU0NGjx4sWqrq5WTk6OduzYoffee0+jRo1KuJ6nn35aF1xwQctI06xZs1ree/nll3XTTTfpgw8+0IEDB3TWWWclXEey8wHITN3VqYsFp90dlmtbp64y4aG6vLzBadgjoHt9Klylw4YNG7Ru3Tpt2rRJAwcO1PTp01VfXy93T/jXUGfTW0+rr297T5NBgz6rx/T9739fZ5xxhlatWqW33npL06dP73K9CxYs0LnnnquioiJddNFFHc7Z6mntyDlz5mjFihV69913NXfuXEmxc7Tq6upUU1Oj/Px8jR07tsO+tNfZX4zz58/XE088oYkTJ+qRRx7Rhg0bejUfgNTrTZ26QyNMia+qy846deg/Ig1XZvaWpP2KXXbRmKi44eHoboQpCvv27VNJSYkGDhyoV155Rc8++6wk6Stf+YquueYavfnmmy2HBYcNG6YZM2bonnvu0V13xdr6/vvvq6SkREceeaS2bdum8ePHa9WqVRo8OPFfXPv27VNZWZkk6ZFHHmmZPmPGDN1///2aPn16y2HBYcOG6aijjtJRRx2l2267TWvXru2wvuOOO05vvfWWXn/99ZZzlk4//fRu93vu3LlauHChdu/erY0bN7a0beTIkcrPz9dTTz2lt99+u8t1TJs2TfPnz9d3vvMdNTY26ve//72uvPJKSdL+/fs1evRoNTQ0aNmyZS37PHjwYO3fv79lHZ3NByBajY37AtWpa1/olzp16P9SMXJ1hrt3HPPtI84++2zdf//9OvnkkzV+/HhNnTpVklRaWqolS5bowgsvVHNzs0aOHKm1a9fqpptu0jXXXKMJEyYoNzdXN998sy688ELdfvvtmjlzpsrLyzVhwoROb1vw7W9/W/PmzdOPf/xjnXnmmS3Tv/Wtb+nVV1/VySefrPz8fC1cuFDXXnutJOmSSy5RXV1dwivsioqK9PDDD+uiiy5qOaH9qquu6na/TzzxRO3fv19lZWUaPXp0y3bOPfdcVVZWqqKiQscdd1yX6zh0gn5FRYWOOeYYnXbaaS3v3Xrrrfryl7+sY445RieddFJLoDoU6u6++26tWLGi0/kA9Exydepq1dTU/netdZ26YxPWqSssLFNOTmFa9gvIJNbTw0ZJrTw2clWZbLiqrKz0zZs3t5m2bds2HX/88RG0rv+49tprNWnSJF1++eXpbkpa8DMCxISoU9c+MB06fEedOqAjM6tJdFQu6pErl/RHM3NJD7j7koi3l3VOOeUUDRo0SHfeeWe6mwIgQu6uhoa6LkNT8nXq2oYo6tQBYUUdrk51951mNlLSWjN7xd2rW89gZldIukKSjj766Iib0//U1NSkuwkAeqltnbrOD9V1Vadu8ODKBHXqylVQcCR16oAUizRcufvO+L+7zGyVpC9Jqm43zxJJS6TYYcEo2wMAqZZcnbqdcm9os1ysTt2YBFfUlbcacaJOHZCJIgtXZjZIUo67748/nyHpX3uyrs5uQwBEec4g0J1wdeo6nutEnTqg74py5OpISavioShP0q/cffXhrqSoqEh79uzR8OHUdUJb7q49e/aoqKgo3U1BP9S6Tl1nteoS16kb2DLClKhOXVFRufLyhvF5BvRjkYUrd39D0sTermfMmDGqra1VXV1dgFahvykqKtKYMWPS3Qz0MbE6dTu7vAHm4dWp+2zkiTp1ADL+Du35+fktJWYAoDuh6tS1r1EXC05HpGGPAPQ1GR+uAOCQpqaPu72irus6deUJ6tTFyq1Qpw5AKIQrABmh8zp1nwWpRHXq8vNHdHNVHXXqAKQW4QpA5MLUqZuWsNwKdeoAZBrCFYAei65OXbkKC4+iTh2APolwBSChQ3XqOrsNwaEg1bFOXU68Tt0YDRx4gkpKZrSpUUedOgD9HeEKyELh6tTN7HCoLhac+GgBkL34BAT6md7WqSsqKqdOHQD0AuEK6EO6qlN36PBd8nXqytuNOFGnDgBCIFwBGSJxnbr2I0/d1alLdEXdGOXnl3LXcABIEcIVkAJR1Kk7dII4deoAILMQroBeClunru2hOurUAUDfQ7gCuhCiTl1xcUWCQ3XlyssbkoY9AgBEjXCFrNW7OnWxEaa2deo+K7dCnToAyF6EK/RLsTp1nYWmw6lTV95uxIk6dQCArhGu0OdQpw4AkMkIV8gYvatTN6qTOnWHRp6oUwcASA3CFVIiZJ261jXqqFMHAMg0hCv0Wpg6dRXUqQMA9At8a6FLPa9Tl6/CwrKWK+ra1qkrjwcn6tQBAPofwlUWo04dAADhEa76qejq1JUrP38Edw0HAKAThKs+qHd16srjwemzK+panyBOnToAAHqHcJVhwtWpa3/zS+rUAQCQCoSrFEpcp67tobqu6tQVFZVTpw4AgAxHuAqkbZ26xFfVJa5TN6wlJH1Wp671qBN16gAA6EsIV0nouk5dbHr3deq+0km5FerUAQDQn2R9uApTp+60NqGpqKhcBQVHUacOAIAslFXhavv2H+ujj17uYZ261ofqqFMHAAASy6pwVVe3QvX1/2ipUzds2FmdlFuhTh0AAOiZrApXkyb9X25FAAAAIpVV9UkIVgAAIGpZFa4AAACiRrgCAAAIiHAFAAAQEOEKAAAgIMIVAABAQIQrAACAgAhXAAAAARGuAAAAAiJcAQAABES4AgAACCjycGVmuWb2gpk9GfW2AAAA0i0VI1fXS9qWgu0AAACkXaThyszGSPqapJ9HuR0AAIBMEfXI1V2Svi2pOeLtAAAAZITIwpWZzZS0y91rupnvCjPbbGab6+rqomoOAABASkQ5cnWqpFlm9pakxySdaWa/bD+Tuy9x90p3rywtLY2wOQAAANGLLFy5+3fdfYy7j5U0V9Kf3P0bUW0PAAAgE3CfKwAAgIDyUrERd98gaUMqtgUAAJBOjFwBAAAERLgCAAAIiHAFAAAQEOEKAAAgIMIVAABAQIQrAACAgAhXAAAAARGuAAAAAiJcAQAABES4AgAACIhwBQAAEBDhCgAAICDCFQAAQECEKwAAgIAIVwAAAAERrgAAAAIiXAEAAAREuAIAAAiIcAUAABAQ4QoAACAgwhUAAEBAhCsAAICACFcAAAABEa4AAAACIlwBAAAERLgCAAAIiHAFAAAQEOEKAAAgIMIVAABAQIQrAACAgAhXAAAAARGuAAAAAiJcAQAABES4AgAACIhwBQAAEBDhCgAAICDCFQAAQECEKwAAgIAIVwAAAAElFa7M7HozG2IxD5rZ82Y2I+rGAQAA9DXJjlx9090/lDRDUqmkBZJuj6xVAAAAfVSy4cri/54j6WF339pqGgAAAOKSDVc1ZvZHxcLVGjMbLKm5qwXMrMjM/mJmW83sr2b2P3vbWAAAgEyXl+R8l0uqkPSGu39sZsMUOzTYlU8lnenuB8wsX9IzZvYf7v5sz5sLAACQ2ZIdufqKpL+7+wdm9g1JN0na19UCHnMg/jI//vAetxQAAKAPSDZc3SfpYzObKOnbkt6WtLS7hcws18y2SNolaa27/7mnDQUAAOgLkg1Xje7uks6T9G/u/m+SBne3kLs3uXuFpDGSvmRmE9rPY2ZXmNlmM9tcV1d3GE0HAADIPMmGq/1m9l1Jl0r6g5nlKnaYLynu/oGkDZLOTvDeEnevdPfK0tLSZFcJAACQkZINVxcrdoL6N939XUllku7oagEzKzWzofHnAyT9V0mv9LypAAAAmS+pcBUPVMskHWFmMyXVu3t351yNlvSUmb0o6TnFzrl6sletBQAAyHBJ3YrBzP6bYiNVGxS7eej/NrMb3X1FZ8u4+4uSJoVoJAAAQF+R7H2uvidpirvvkmKH/CStk9RpuAIAAMhGyZ5zlXMoWMXtOYxlAQAAskayI1erzWyNpF/HX18s6d+jaRIAAEDflVS4cvcbzWy2pFMVO+dqibuvirRlAAAAfVCyI1dy95WSVkbYFgAAgD6vy3BlZvuVuB6gKVY+cEgkrQIAAOijugxX7t5tiRsAAAB8hiv+AAAAAiJcAQAABES4AgAACIhwBQAAEBDhCgAAICDCFQAAQECEKwAAgIAIVwAAAAERrgAAAAIiXAEAAAREuAIAAAiIcAUAABAQ4QoAACAgwhUAAEBAhCsAAICACFcAAAABEa4AAAACIlwBAAAERLgCAAAIiHAFAAAQEOEKAAAgIMIVAABAQIQrAACAgAhXAAAAARGuAAAAAiJcAQAABES4AgAACIhwBQAAEBDhCgAAICDCFQAAQECEKwAAgIAIVwAAAAERrgAAAAIiXAEAAAREuAIAAAiIcAUAABBQZOHKzMrN7Ckz22ZmfzWz66PaFgAAQKbIi3DdjZL+u7s/b2aDJdWY2Vp3/1uE2wQAAEiryEau3P0dd38+/ny/pG2SyqLaHgAAQCZIyTlXZjZW0iRJf07w3hVmttnMNtfV1aWiOQAAAJGJPFyZWbGklZKq3P3D9u+7+xJ3r3T3ytLS0qibAwAAEKlIw5WZ5SsWrJa5++NRbgsAACATRHm1oEl6UNI2d/9xVNsBAADIJFGOXJ0q6VJJZ5rZlvjjnAi3BwAAkHaR3YrB3Z+RZFGtHwAAIBNxh3YAAICACFcAAAABEa4AAAACIlwBAAAERLgCAAAIiHAFAAAQEOEKAAAgIMIVAABAQIQrAACAgAhXAAAAARGuAAAAAiJcAQAABES4AgAACIhwBQAAEBDhCgAAICDCFQAAQECEKwAAgIAIVwAAAAERrgAAAAIiXAEAAAREuAIAAAiIcAUAABAQ4QoAACAgwhUAAEBAhCsAAICACFcAAAABEa4AAAACIlwBAAAERLgCAAAIiHAFAAAQEOEKAAAgIMIVAABAQIQrAACAgAhXAAAAARGuAAAAAiJcAQAABES4AgAACIhwBQAAEBDhCgAAICDCFQAAQECEKwAAgIAIVwAAAAFFFq7M7CEz22VmL0e1DQAAgEwT5cjVI5LOjnD9AAAAGSeycOXu1ZL2RrV+AACATMQ5VwAAAAGlPVyZ2RVmttnMNtfV1aW7OQAAAL2S9nDl7kvcvdLdK0tLS9PdHAAAgF5Je7gCAADoT6K8FcOvJW2SNN7Mas3s8qi2BQAAkCnyolqxu389qnUDAABkKg4LAgAABES4AgAACIhwBQAAEBDhCgAAICDCFQAAQECEKwAAgIAIVwAAAAERrgAAAAIiXAEAAAREuAIAAAiIcAUAABAQ4QoAACAgwhUAAEBAhCsAAICA8tLdgFTa8NYG7avf1+PlXd7zZb3ny/Z222w/u7efzfvO9vnZY/vZuf28nDxdPeXqXm2/N7IqXFWtrtLW97amuxkAACBCA/IGEK5S5dezf636xvpercPMer6ser5sb7fN9rN7+9m872yfnz22n73bT5esClfHlx6f7iYAAIB+jhPaAQAAAiJcAQAABES4AgAACIhwBQAAEBDhCgAAICDCFQAAQECEKwAAgIAIVwAAAAERrgAAAAIiXAEAAARkva1aHZKZ1Ul6O+LNjJC0O+Jt4PDQJ5mJfsk89Elmol8yT6r65Bh3L20/MaPCVSqY2WZ3r0x3O/AZ+iQz0S+Zhz7JTPRL5kl3n3BYEAAAICDCFQAAQEDZGK6WpLsB6IA+yUz0S+ahTzIT/ZJ50tonWXfOFQAAQJSyceQKAAAgMv02XJnZ2Wb2dzN73cy+k+B9M7O74++/aGaT09HObJJEn1wS74sXzew/zWxiOtqZTbrrk1bzTTGzJjObk8r2Zatk+sXMppvZFjP7q5ltTHUbs00Sn19HmNnvzWxrvE8WpKOd2cTMHjKzXWb2cifvp+973t373UNSrqT/J+lzkgokbZV0Qrt5zpH0H5JM0lRJf053u/vzI8k++SdJJfHn/0yfpL9PWs33J0n/LmlOutvd3x9J/q4MlfQ3SUfHX49Md7v78yPJPlks6X/Fn5dK2iupIN1t788PSdMkTZb0cifvp+17vr+OXH1J0uvu/oa7H5T0mKTz2s1znqSlHvOspKFmNjrVDc0i3faJu/+nu78ff/mspDEpbmO2Seb3RJKuk7RS0q5UNi6LJdMv/yLpcXf/hyS5O30TrWT6xCUNNjOTVKxYuGpMbTOzi7tXK/b/3Jm0fc/313BVJml7q9e18WmHOw/COdz/78sV+4sD0em2T8ysTNIFku5PYbuyXTK/K8dKKjGzDWZWY2aXpax12SmZPrlH0vGSdkp6SdL17t6cmuahE2n7ns9LxUbSwBJMa39ZZDLzIJyk/7/N7AzFwtV/ibRFSKZP7pK0yN2bYn+QIwWS6Zc8SadI+qqkAZI2mdmz7v5q1I3LUsn0yVmStkg6U9LnJa01s6fd/cOI24bOpe17vr+Gq1pJ5a1ej1Hsr4nDnQfhJPX/bWYnS/q5pH929z0palu2SqZPKiU9Fg9WIySdY2aN7v5ESlqYnZL9/Nrt7h9J+sjMqiVNlES4ikYyfbJA0u0eO9nndTN7U9Jxkv6SmiYigbR9z/fXw4LPSfqimY0zswJJcyX9rt08v5N0WfxqgqmS9rn7O6luaBbptk/M7GhJj0u6lL/AU6LbPnH3ce4+1t3HSloh6WqCVeSS+fz6raTTzCzPzAZK+rKkbSluZzZJpk/+odhIoszsSEnjJb2R0laivbR9z/fLkSt3bzSzayWtUewqj4fc/a9mdlX8/fsVu/LpHEmvS/pYsb86EJEk++R/SBou6afxkZJGpxhqZJLsE6RYMv3i7tvMbLWkFyU1S/q5uye8HB29l+Tvyq2SHjGzlxQ7HLXI3XenrdFZwMx+LWm6pBFmVivpZkn5Uvq/57lDOwAAQED99bAgAABAWhCuAAAAAiJcAQAABES4AgAACIhwBQAAEBDhCkDWM7PpZvZkutsBoH8gXAEAAAREuALQZ5jZN8zsL2a2xcweMLNcMztgZnea2fNmtt7MSuPzVpjZs2b2opmtMrOS+PQvmNk6M9saX+bz8dUXm9kKM3vFzJYZxRQB9BDhCkCfYGbHS7pY0qnuXiGpSdIlkgZJet7dJ0vaqNhdmiVpqWJ3yT5Z0kutpi+TdK+7T5T0T5IOlcOYJKlK0gmSPifp1Ih3CUA/1S/L3wDol74q6RRJz8UHlQZI2qVY+ZffxOf5paTHzewISUPdfWN8+i8k/R8zGyypzN1XSZK710tSfH1/cffa+OstksZKeibyvQLQ7xCuAPQVJukX7v7dNhPNvt9uvq5qenV1qO/TVs+bxOcjgB7isCCAvmK9pDlmNlKSzGyYmR2j2OfYnPg8/yLpGXffJ+l9MzstPv1SSRvd/UNJtWZ2fnwdhWY2MJU7AaD/4y8zAH2Cu//NzG6S9Eczy5HUIOkaSR9JOtHMaiTtU+y8LEmaJ+n+eHh6Q9KC+PRLJT1gZv8aX8dFKdwNAFnA3LsaQQeAzGZmB9y9ON3tAIBDOCwIAAAQECNXAAAAATFyBQAAEBDhCgAAICDCFQAAQECEKwAAgIAIVwAAAAERrgAAAAL6/zlb8l7FtopVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"train loss\", c='b')\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(val_losses, label=\"val loss\", c='y')\n",
    "plt.plot(val_acc, label=\"accuracy of val data\", c='g')\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aadde115",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['entailment', 'neutral', 'contradiction']\n",
    "\n",
    "def bertPredict(model, b_input_ids, b_attn_mask, FINETUNE):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(b_input_ids, b_attn_mask)\n",
    "        if FINETUNE:\n",
    "            logits = logits[\"logits\"]\n",
    "    preds = torch.argmax(logits, dim=1).flatten()\n",
    "    predictions = []\n",
    "    for pred in preds.cpu().numpy():\n",
    "        predictions.append(label[pred])\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def evaluateRandomly(model, test_dataloader, n=1, FINETUNE=False):\n",
    "    for i, sample in enumerate(test_dataloader):\n",
    "        if i > n: break\n",
    "            \n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in sample)\n",
    "        predict = bertPredict(model, b_input_ids, b_attn_mask, FINETUNE)\n",
    "        b_labels = b_labels.cpu().numpy()\n",
    "        for i, pred in enumerate(b_labels):\n",
    "            print(\"label: {} --- predict: {}\".format(label[b_labels[i]], predict[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c22f4914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test dataset: 59.46661237785016\n",
      "label: neutral --- predict: neutral\n",
      "label: entailment --- predict: entailment\n",
      "label: contradiction --- predict: entailment\n",
      "label: neutral --- predict: neutral\n",
      "label: entailment --- predict: neutral\n",
      "label: contradiction --- predict: neutral\n",
      "label: entailment --- predict: entailment\n",
      "label: neutral --- predict: neutral\n",
      "label: contradiction --- predict: entailment\n",
      "label: neutral --- predict: neutral\n",
      "label: entailment --- predict: entailment\n",
      "label: contradiction --- predict: neutral\n",
      "label: entailment --- predict: neutral\n",
      "label: entailment --- predict: entailment\n",
      "label: contradiction --- predict: entailment\n",
      "label: contradiction --- predict: entailment\n",
      "label: entailment --- predict: entailment\n",
      "label: neutral --- predict: neutral\n",
      "label: entailment --- predict: entailment\n",
      "label: contradiction --- predict: entailment\n",
      "label: neutral --- predict: entailment\n",
      "label: contradiction --- predict: entailment\n",
      "label: entailment --- predict: entailment\n",
      "label: neutral --- predict: entailment\n",
      "label: neutral --- predict: neutral\n",
      "label: contradiction --- predict: entailment\n",
      "label: entailment --- predict: entailment\n",
      "label: entailment --- predict: entailment\n",
      "label: neutral --- predict: neutral\n",
      "label: contradiction --- predict: entailment\n",
      "label: contradiction --- predict: entailment\n",
      "label: entailment --- predict: entailment\n",
      "label: entailment --- predict: entailment\n",
      "label: entailment --- predict: entailment\n",
      "label: neutral --- predict: neutral\n",
      "label: contradiction --- predict: entailment\n",
      "label: neutral --- predict: neutral\n",
      "label: entailment --- predict: entailment\n",
      "label: contradiction --- predict: entailment\n",
      "label: entailment --- predict: entailment\n",
      "label: neutral --- predict: neutral\n",
      "label: contradiction --- predict: entailment\n",
      "label: contradiction --- predict: entailment\n",
      "label: entailment --- predict: neutral\n",
      "label: neutral --- predict: neutral\n",
      "label: neutral --- predict: neutral\n",
      "label: contradiction --- predict: neutral\n",
      "label: entailment --- predict: entailment\n",
      "label: neutral --- predict: neutral\n",
      "label: contradiction --- predict: entailment\n",
      "label: neutral --- predict: neutral\n",
      "label: entailment --- predict: entailment\n",
      "label: contradiction --- predict: entailment\n",
      "label: neutral --- predict: entailment\n",
      "label: contradiction --- predict: entailment\n",
      "label: entailment --- predict: entailment\n",
      "label: entailment --- predict: entailment\n",
      "label: contradiction --- predict: entailment\n",
      "label: neutral --- predict: neutral\n",
      "label: entailment --- predict: entailment\n",
      "label: contradiction --- predict: entailment\n",
      "label: neutral --- predict: neutral\n",
      "label: neutral --- predict: neutral\n",
      "label: entailment --- predict: entailment\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = generateDataset(dataPath='./dataset/snli_1.0_test.jsonl', isTrain=False)\n",
    "test_loss, test_acc = evaluate(model, loss_fn, test_dataloader, device=device, FINETUNE=True)\n",
    "print(\"Accuracy on test dataset: {}\".format(test_acc))\n",
    "evaluateRandomly(model, test_dataloader, FINETUNE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0be39c",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
