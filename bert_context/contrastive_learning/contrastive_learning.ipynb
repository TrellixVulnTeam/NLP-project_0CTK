{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma6yDvOBQ1hN",
        "outputId": "f28cb0d3-59cd-48be-fe89-62371f311d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Nov 24 09:47:50 2021\n",
        "\n",
        "@author: cordeliazhu\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "os.system(\"pip install transformers==3.4.0\")\n",
        "#from transformers import  BertTokenizer, BertConfig, BertModel\n",
        "from transformers import AdamW\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from transformers import BertTokenizer, BertModel, BertConfig\n",
        "import scipy.stats\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVrvIDgnSnwb",
        "outputId": "18179446-39e1-44c8-dca0-ebe6e73444b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We are using cuda device\n",
            "Epoch 1 begins\n",
            "-------------------------------\n",
            "loss: 4.058414  [    0/149145]\n",
            "corrcoef for test: 0.208167\n",
            "Higher corrcoef: 0.208167%, Saved PyTorch Model State to model.bin\n",
            "loss: 2.242266  [  320/149145]\n",
            "corrcoef for test: 0.641226\n",
            "Higher corrcoef: 0.641226%, Saved PyTorch Model State to model.bin\n",
            "loss: 1.159838  [  640/149145]\n",
            "corrcoef for test: 0.700999\n",
            "Higher corrcoef: 0.700999%, Saved PyTorch Model State to model.bin\n",
            "loss: 1.454275  [  960/149145]\n",
            "corrcoef for test: 0.711446\n",
            "Higher corrcoef: 0.711446%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.998149  [ 1280/149145]\n",
            "corrcoef for test: 0.722839\n",
            "Higher corrcoef: 0.722839%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.739120  [ 1600/149145]\n",
            "corrcoef for test: 0.730639\n",
            "Higher corrcoef: 0.730639%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.759683  [ 1920/149145]\n",
            "corrcoef for test: 0.734833\n",
            "Higher corrcoef: 0.734833%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.999541  [ 2240/149145]\n",
            "corrcoef for test: 0.737169\n",
            "Higher corrcoef: 0.737169%, Saved PyTorch Model State to model.bin\n",
            "loss: 1.014861  [ 2560/149145]\n",
            "corrcoef for test: 0.740568\n",
            "Higher corrcoef: 0.740568%, Saved PyTorch Model State to model.bin\n",
            "loss: 1.155204  [ 2880/149145]\n",
            "corrcoef for test: 0.740947\n",
            "Higher corrcoef: 0.740947%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.789407  [ 3200/149145]\n",
            "corrcoef for test: 0.742985\n",
            "Higher corrcoef: 0.742985%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.764467  [ 3520/149145]\n",
            "corrcoef for test: 0.744857\n",
            "Higher corrcoef: 0.744857%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.735832  [ 3840/149145]\n",
            "corrcoef for test: 0.745204\n",
            "Higher corrcoef: 0.745204%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.600851  [ 4160/149145]\n",
            "corrcoef for test: 0.752710\n",
            "Higher corrcoef: 0.752710%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.653077  [ 4480/149145]\n",
            "corrcoef for test: 0.755609\n",
            "Higher corrcoef: 0.755609%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.706708  [ 4800/149145]\n",
            "corrcoef for test: 0.762476\n",
            "Higher corrcoef: 0.762476%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.541943  [ 5120/149145]\n",
            "corrcoef for test: 0.765100\n",
            "Higher corrcoef: 0.765100%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.674367  [ 5440/149145]\n",
            "corrcoef for test: 0.764213\n",
            "loss: 0.763644  [ 5760/149145]\n",
            "corrcoef for test: 0.762529\n",
            "loss: 0.409620  [ 6080/149145]\n",
            "corrcoef for test: 0.760778\n",
            "loss: 0.341589  [ 6400/149145]\n",
            "corrcoef for test: 0.758294\n",
            "loss: 1.013267  [ 6720/149145]\n",
            "corrcoef for test: 0.760787\n",
            "loss: 0.771599  [ 7040/149145]\n",
            "corrcoef for test: 0.767552\n",
            "Higher corrcoef: 0.767552%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.560801  [ 7360/149145]\n",
            "corrcoef for test: 0.768646\n",
            "Higher corrcoef: 0.768646%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.788043  [ 7680/149145]\n",
            "corrcoef for test: 0.767740\n",
            "loss: 0.401472  [ 8000/149145]\n",
            "corrcoef for test: 0.767125\n",
            "loss: 0.741640  [ 8320/149145]\n",
            "corrcoef for test: 0.770529\n",
            "Higher corrcoef: 0.770529%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.502598  [ 8640/149145]\n",
            "corrcoef for test: 0.773537\n",
            "Higher corrcoef: 0.773537%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.390990  [ 8960/149145]\n",
            "corrcoef for test: 0.773058\n",
            "loss: 0.553215  [ 9280/149145]\n",
            "corrcoef for test: 0.772680\n",
            "loss: 0.597565  [ 9600/149145]\n",
            "corrcoef for test: 0.775055\n",
            "Higher corrcoef: 0.775055%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.783378  [ 9920/149145]\n",
            "corrcoef for test: 0.774786\n",
            "loss: 0.788918  [10240/149145]\n",
            "corrcoef for test: 0.774355\n",
            "loss: 0.328992  [10560/149145]\n",
            "corrcoef for test: 0.776345\n",
            "Higher corrcoef: 0.776345%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.701036  [10880/149145]\n",
            "corrcoef for test: 0.775873\n",
            "loss: 0.801248  [11200/149145]\n",
            "corrcoef for test: 0.773559\n",
            "loss: 0.322578  [11520/149145]\n",
            "corrcoef for test: 0.773307\n",
            "loss: 0.628621  [11840/149145]\n",
            "corrcoef for test: 0.773153\n",
            "loss: 0.719174  [12160/149145]\n",
            "corrcoef for test: 0.769831\n",
            "loss: 0.619753  [12480/149145]\n",
            "corrcoef for test: 0.770467\n",
            "loss: 0.777344  [12800/149145]\n",
            "corrcoef for test: 0.770675\n",
            "loss: 0.760362  [13120/149145]\n",
            "corrcoef for test: 0.772359\n",
            "loss: 1.081025  [13440/149145]\n",
            "corrcoef for test: 0.776845\n",
            "Higher corrcoef: 0.776845%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.429450  [13760/149145]\n",
            "corrcoef for test: 0.776918\n",
            "Higher corrcoef: 0.776918%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.498311  [14080/149145]\n",
            "corrcoef for test: 0.774529\n",
            "loss: 0.673955  [14400/149145]\n",
            "corrcoef for test: 0.771832\n",
            "loss: 0.398362  [14720/149145]\n",
            "corrcoef for test: 0.771724\n",
            "loss: 0.363788  [15040/149145]\n",
            "corrcoef for test: 0.774358\n",
            "loss: 0.442398  [15360/149145]\n",
            "corrcoef for test: 0.776326\n",
            "loss: 0.638973  [15680/149145]\n",
            "corrcoef for test: 0.776293\n",
            "loss: 0.516676  [16000/149145]\n",
            "corrcoef for test: 0.773482\n",
            "loss: 0.422051  [16320/149145]\n",
            "corrcoef for test: 0.772898\n",
            "loss: 0.464436  [16640/149145]\n",
            "corrcoef for test: 0.777396\n",
            "Higher corrcoef: 0.777396%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.657652  [16960/149145]\n",
            "corrcoef for test: 0.779299\n",
            "Higher corrcoef: 0.779299%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.903881  [17280/149145]\n",
            "corrcoef for test: 0.778566\n",
            "loss: 0.352138  [17600/149145]\n",
            "corrcoef for test: 0.777998\n",
            "loss: 0.495611  [17920/149145]\n",
            "corrcoef for test: 0.780018\n",
            "Higher corrcoef: 0.780018%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.851101  [18240/149145]\n",
            "corrcoef for test: 0.780607\n",
            "Higher corrcoef: 0.780607%, Saved PyTorch Model State to model.bin\n",
            "loss: 0.482458  [18560/149145]\n",
            "corrcoef for test: 0.779366\n",
            "loss: 0.753459  [18880/149145]\n",
            "corrcoef for test: 0.776571\n",
            "loss: 0.262786  [19200/149145]\n",
            "corrcoef for test: 0.775265\n",
            "loss: 0.626702  [19520/149145]\n",
            "corrcoef for test: 0.775173\n",
            "loss: 0.352310  [19840/149145]\n",
            "corrcoef for test: 0.779180\n",
            "loss: 0.536840  [20160/149145]\n",
            "corrcoef for test: 0.777435\n",
            "loss: 0.479821  [20480/149145]\n",
            "corrcoef for test: 0.775193\n",
            "loss: 0.556618  [20800/149145]\n",
            "corrcoef for test: 0.773988\n",
            "loss: 0.804063  [21120/149145]\n",
            "corrcoef for test: 0.771114\n",
            "loss: 0.545765  [21440/149145]\n",
            "corrcoef for test: 0.771351\n",
            "loss: 0.508649  [21760/149145]\n",
            "corrcoef for test: 0.773017\n",
            "Corrcoef didn't up for 11 batch, early stop!\n",
            "Training step has finished\n",
            "Deving step has started\n",
            "dev corrcoef is: 0.783557\n"
          ]
        }
      ],
      "source": [
        "# use gpu or not\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(\"We are using {} device\".format(device))\n",
        "\n",
        "# get the tokneizer and configure from huggingface\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "Config = BertConfig.from_pretrained('bert-base-uncased')\n",
        "# we choose cls as our output method\n",
        "output_method = 'cls'\n",
        "# resource is limited\n",
        "batch_size = 32\n",
        "learning_rate = 2e-5\n",
        "maxlen = 32\n",
        "\n",
        "file_path = \"/content/gdrive/My Drive/STS_SNLI/\"\n",
        "test_file = 'sts-test.csv'\n",
        "dev_file = 'sts-dev.csv'\n",
        "\n",
        "\n",
        "\n",
        "def snli_data(snli_path):\n",
        "    data = []\n",
        "    with open(snli_path) as f:\n",
        "        for i in f:\n",
        "            data.append(json.loads(i))\n",
        "    return data\n",
        "\n",
        "def STS_data(STS_path):\n",
        "    data = []\n",
        "    with open(STS_path) as f:\n",
        "        for i in f:\n",
        "            d = i.split(\"\\t\")\n",
        "            sentence1 = d[5]\n",
        "            sentence2 = d[6]\n",
        "            score = float(d[4])\n",
        "            data.append([sentence1,sentence2,score])\n",
        "    return data\n",
        "snli_file_path = \"/content/gdrive/My Drive/STS_SNLI/\"\n",
        "snli_train_file = 'snli_1.0_trainproceed.txt'\n",
        "# save our pre-trained model\n",
        "save_path = \"/content/gdrive/My Drive/STS_SNLI/pytorch_model.bin\"\n",
        "\n",
        "snil_vocab = snli_data(os.path.join(snli_file_path, snli_train_file))\n",
        "# shuffle the snil train data\n",
        "np.random.shuffle(snil_vocab)\n",
        "# load the test data\n",
        "test_data = STS_data(os.path.join(file_path, test_file))\n",
        "# load the dev data\n",
        "dev_data = STS_data(os.path.join(file_path, dev_file))\n",
        "\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, maxlen, transform=None, target_transform=None):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.maxlen = maxlen\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def text_to_id(self, json_data):\n",
        "      # get the origin from the txt file\n",
        "        origin = json_data['origin']\n",
        "        entailment = json_data['entailment']\n",
        "        contradiction = json_data['contradiction']\n",
        "        sample = self.tokenizer([origin,entailment,contradiction], max_length=self.maxlen, truncation=True, padding='max_length', return_tensors='pt')\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.text_to_id(self.data[idx])\n",
        "\n",
        "\n",
        "class TestDataset:\n",
        "    def __init__(self, data, tokenizer, maxlen):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.maxlen = maxlen\n",
        "        self.traget_idx = self.text_to_id([x[0] for x in data])\n",
        "        self.source_idx = self.text_to_id([x[1] for x in data])\n",
        "        # get the score from float to int\n",
        "        self.label_list = [int(x[2]) for x in data]\n",
        "        assert len(self.traget_idx['input_ids']) == len(self.source_idx['input_ids'])\n",
        "\n",
        "    def text_to_id(self,source):\n",
        "    \n",
        "      # repeated twice the source could make label matrix more clear\n",
        "        sample = self.tokenizer(source, max_length = self.maxlen, truncation=True, padding = 'max_length', return_tensors='pt')\n",
        "        return sample\n",
        "\n",
        "    def get_data(self):\n",
        "        return self.traget_idx, self.source_idx, self.label_list\n",
        "\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, output_method):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased',config=Config)\n",
        "        self.output_method = output_method\n",
        "        assert output_method in ['cls','pooler']\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        x1 = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        if self.output_method == 'cls':\n",
        "            last_hidden_state = x1[0]\n",
        "            output = last_hidden_state[:,0]\n",
        "       \n",
        "        return output\n",
        "\n",
        "model = NeuralNetwork(output_method).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n",
        "\n",
        "training_data = TrainDataset(snil_vocab, tokenizer, maxlen)\n",
        "train_dataloader = DataLoader(training_data, batch_size = batch_size)\n",
        "\n",
        "testing_data = TestDataset(test_data, tokenizer, maxlen)\n",
        "deving_data = TestDataset(dev_data, tokenizer, maxlen)\n",
        "\n",
        "# measures the linear relationship between two datasets. \n",
        "# > 0.8 strong relation\n",
        "def compute_corrcoef(x, y):\n",
        "    return scipy.stats.spearmanr(x, y).correlation\n",
        "# infoNCE loss\n",
        "def compute_loss(y_pred, lamda=0.05):\n",
        "    row = torch.arange(0,y_pred.shape[0],3,device='cuda')\n",
        "    col = torch.arange(y_pred.shape[0], device='cuda')\n",
        "    # we need to mask the diagnal because it must be 1 do not have loss\n",
        "    col = torch.where(col % 3 != 0)[0].cuda()\n",
        "    # we need to divide our label into odd and even\n",
        "    y_true = torch.arange(0,len(col),2,device='cuda')\n",
        "    # caculate score and loss\n",
        "    similarities = F.cosine_similarity(y_pred.unsqueeze(1), y_pred.unsqueeze(0), dim=2)\n",
        "    # use python default fast cacuation of matrix\n",
        "    similarities = torch.index_select(similarities, 0, row)\n",
        "     # get x follow by row\n",
        "    similarities = torch.index_select(similarities, 1, col)\n",
        "    # lambda is the tempature\n",
        "    similarities = similarities / lamda\n",
        "    # cross_entropy，cross_entropy_loss!!! the key point for contrastive learning--- let positive sample clse let negative samples away\n",
        "    loss = F.cross_entropy(similarities, y_true)\n",
        "    return torch.mean(loss)\n",
        "\n",
        "def test(test_data,model):\n",
        "    traget_idx, source_idx, label_list = test_data.get_data()\n",
        "\n",
        "# To perform inference without Gradient Calculation.\n",
        "# To make sure there's no leak test data into the model.\n",
        "    with torch.no_grad():\n",
        "        # get input ids\n",
        "        traget_ids = traget_idx['input_ids'].to(device)\n",
        "        source_ids = source_idx['input_ids'].to(device)\n",
        "        # get attention\n",
        "        traget_attention_mask = traget_idx['attention_mask'].to(device)\n",
        "        source_attention_mask = source_idx['attention_mask'].to(device)\n",
        "        # get token types\n",
        "        traget_token_type_ids = traget_idx['token_type_ids'].to(device)\n",
        "        source_token_type_ids = source_idx['token_type_ids'].to(device)\n",
        "        # get pred result\n",
        "        traget_pred = model(traget_ids,traget_attention_mask,traget_token_type_ids)\n",
        "        source_pred = model(source_ids,source_attention_mask,source_token_type_ids)\n",
        "        # list of labels\n",
        "        similarity = F.cosine_similarity(traget_pred,source_pred)\n",
        "        similarity = similarity.cpu().numpy()\n",
        "        label = np.array(label_list)\n",
        "        corrcoef = compute_corrcoef(label,similarity)\n",
        "    return corrcoef\n",
        "\n",
        "def train(dataloader,testdata, model, optimizer):\n",
        "    model.train()\n",
        "    size = len(dataloader.dataset)\n",
        "    max_corrcoef = 0\n",
        "    stop_increase_n = 0\n",
        "    for batch, data in enumerate(dataloader):\n",
        "        input_ids = data['input_ids'].view(len(data['input_ids'])*3,-1).to(device)\n",
        "        attention_mask = data['attention_mask'].view(len(data['attention_mask'])*3,-1).to(device)\n",
        "        token_type_ids = data['token_type_ids'].view(len(data['token_type_ids'])*3,-1).to(device)\n",
        "        pred = model(input_ids,attention_mask,token_type_ids)\n",
        "        loss = compute_loss(pred)\n",
        "        # zero grad otherwise cuda out of resource\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * int(len(input_ids)/3)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            model.eval() \n",
        "            corrcoef = test(testdata,model)\n",
        "            model.train()\n",
        "            print(f\"corrcoef for test: {corrcoef:>4f}\")\n",
        "\n",
        "            if corrcoef > max_corrcoef:\n",
        "                stop_increase_n = 0\n",
        "                max_corrcoef = max(corrcoef, max_corrcoef)\n",
        "                torch.save(model.state_dict(),save_path)\n",
        "                print(f\"Current corrcoef is: {(max_corrcoef):>4f}%, saved PyTorch Model to model.bin\")\n",
        "            else:\n",
        "                # early stop\n",
        "                stop_increase_n += 1\n",
        "                if stop_increase_n > 10:\n",
        "                    print(f\"Corrcoef didn't increase for 10 batch, next epoch beigns\" )\n",
        "                    break\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    epochs = 1\n",
        "    for t in range(epochs):\n",
        "        print(f\"Epoch {t + 1} begins\\n-------------------------------\")\n",
        "        train(train_dataloader,testing_data, model, optimizer)\n",
        "    print(\"Training step has finished\")\n",
        "\n",
        "    print(\"Deving step has started\")\n",
        "    save_path = \"/content/gdrive/My Drive/STS_SNLI/pytorch_model.bin\"\n",
        "    model.load_state_dict(torch.load(save_path))\n",
        "    corrcoef = test(deving_data,model)\n",
        "    print(f\"dev corrcoef is: {corrcoef:>4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mCCK7OfUu0y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "simCSE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
